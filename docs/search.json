[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Gabriele Midolo",
    "section": "",
    "text": "Welcome - and thanks for visiting!\nIn this website you can check my condensed CV and my data portfolio.\nMy current work as researcher investigates the temporal and spatial organization of species, particularly plants, and their functional trait variation. I employ quantitative syntheses of large databases to uncover common patterns across a wide range of biomes and species.\n\n\n\nPlebejus (Plebejus) argus (Linnaeus, 1758) - Lycaenidae Polyommatinae Polyommatini\nDrawing by G. Midolo"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Gabriele Midolo",
    "section": "",
    "text": "A plant ecologist by training, I bring 8+ years of research experience from various European scientific settings. My daily practice involves the integrated application of advanced R programming, machine learning, and GIS to effectively address my research questions.\n\nComputer Skills\nProgramming Languages & Environments:\n\nR [expert]\n\nData management in SQL (DBI) and manipulation (tidyverse)\nStatistical analyses and modeling (including Machine Learning with tidymodels)\nData visualization (e.g., ggplot, leaflet, plotly)\nSpatial data analysis:\n\nGIS / Simple Features (sf)\nRaster Data (terra)\n\n\nPython [advanced]\n\nSupervised ML (sklearn)\nData manipulation (pandas, geopandas)\n\nmySQL & PostgreSQL [basic]\nR Markdown, LaTeX, Quarto (creating dynamic reports and documentations) [advanced]\nGit & GitHub [advanced]\n\n\n\n\n\n\n\n\n\nEducation & Employment History\n\n\n\n\n\n\n\n\n\n\n\n\n\nPostdoctoral fellow (2024 - current) at MOBI lab - Czech University of Life Sciences, Prague (Czech Republic);\nResearcher (III level) (2023) at CNR-IRET - National Research Council of Italy, Pisa (Italy);\nPostdoctoral fellow (2021 - 2023) at the Vegetation Science Group of the Department of Botany and Zoology, Masaryk University, Brno (Czech Republic);\nPhD in Mountain Environment & Agriculture (2017 - 2021) cum laude at the Free University of Bozen-Bolzano, Bolzano (Italy). Thesis title: “Meta-analyses upon the intraspecific plant trait variability within the environmental and geographic space” (supervisor: Camilla Wellstein);\nVisiting PhD student (2020, 6 months) at the Antonelli Lab, Gothenburg Global Biodiversity Centre - University of Gothenburg, Gothenburg (Sweden);\nMSc Environmental Science (2015 - 2017) at Wageningen University & Research, Wageningen (The Netherlands). MSc thesis at the ESA group: “Plant biodiversity loss following increased atmospheric nitrogen deposition: A systematic review” (supervisors: Wim De Vries; Rob Alkemade); \nIntern (MSc Internship) (2017, 4 months) at Forest & Nature Lab – Department of Forest and Water Management – Ghent University, Ghent (Belgium);\nBSc Forest Science (2011 - 2014) at University of Turin, Turin (Italy) cum laude. Thesis title (in Italian): “Redox reactions in the soil and their environmental significance” (supervisor: Franco Ajmone Marsan).\n\n\n\n\nLead Author Scientific Publications\n\nMidolo, G., Skokanová, H., Clark, A. T., Vymazalová, M., Chytrý, M., Dullinger, S., … & Keil, P. (2025) Nineteenth-century land use shapes the current occurrence of some plant species, but weakly affects the richness and total composition of Central European grasslands. Landscape Ecology, 40(1), 22. https://doi.org/10.1007/s10980-024-02016-6\nMidolo, G. (2024) Plant functional traits couple with range size and shape in European trees Global Ecology and Biogeography, e13838. https://doi.org/10.1111/geb.13838\nMidolo, G., Axmanová, I., Divíšek, J., Dřevojan, P., Lososová, Z., Večeřa, M., … & Chytrý, M. (2024). Diversity and distribution of Raunkiær’s life forms in European vegetation. Journal of Vegetation Science, 35(1), e13229. https://doi.org/10.1111/jvs.13229\nMidolo, G., Mendez-Castro, F. & Ottaviani, G. (2023) Why studying the response of trait coordination to insularity matters? Journal of Biogeography, 00, 1–9. https://doi.org/10.1111/JBI.14706\nMidolo, G., Herben, T., Axmanová, I., Marcenò, C., Pätsch, R., Bruelheide, H., … & Chytrý, M. (2022). Disturbance indicator values for European plants. Global Ecology and Biogeography, 32(1), 24-34. https://doi.org/10.1111/geb.13603\nMidolo, G., Kuss, P., & Wellstein, C. (2021). Land use and water availability drive community-level plant functional diversity of grasslands along a temperature gradient in the Swiss Alps. Science of The Total Environment, 764, 142888. https://doi.org/10.1016/j.scitotenv.2020.142888\nMidolo, G., Wellstein, C., & Faurby, S. (2021). Individual fitness is decoupled from coarse‐scale probability of occurrence in North American trees. Ecography, 44(5), 789-801. https://doi.org/10.1111/ecog.05446\nMidolo, G., & Wellstein, C. (2020). Plant performance and survival across transplant experiments depend upon temperature and precipitation change along elevation. Journal of Ecology, 108(5), 2107-2120 https://doi.org/10.1111/1365-2745.13387\nMidolo, G., De Frenne, P., Hölzel, N., & Wellstein, C. (2019). Global patterns of intraspecific leaf trait responses to elevation. Global Change Biology, 25(7), 2485–2498. https://doi.org/10.1111/gcb.14646\nMidolo, G., Alkemade, R., Schipper, A. M., Benítez‐López, A., Perring, M. P., & de Vries, W. (2019). Impacts of nitrogen addition on plant species richness and abundance: A global meta‐analysis. Global Ecology and Biogeography, 28(3), 398–413. https://doi.org/10.1111/geb.12856"
  },
  {
    "objectID": "cv.html#education-and-employment-history",
    "href": "cv.html#education-and-employment-history",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Researcher (III level) (2023 - current) at National Research Council of Italy (CNR), Pisa (Italy);\nPostdoctoral fellow (2021 - 2023) at the Department of Botany and Zoology, Masaryk University, Brno (Czech Republic);\nPhD in Mountain Environment & Agriculture (2017 - 2021) cum laudeat Free University of Bozen-Bolzano, Bolzano (Italy). Thesis title: \"Meta-analyses upon the intraspecific plant trait variability within the environmental and geographic space\" (supervisor: Camilla Wellstein);\nVisiting PhD student(2020, 6 months) at the Antonelli Lab, Gothenburg Global Biodiversity Centre - University of Gothenburg, Gothenburg (Sweden);\nMSc Environmental Science (2015 - 2017) at Wageningen University & Research, Wageningen (The Netherlands). Thesis title: \"Plant biodiversity loss following increased atmospheric nitrogen deposition: A systematic review\" (supervisors: Wim De Vries; Rob Alkemade); \nIntern (MSc Internship) (2017, 4 months) at Forest & Nature Lab – Department of Forest and Water Management – Ghent University, Ghent (Belgium);\nBSc Forest Science (2011 - 2014) at University of Turin, Turin (Italy) 110 cum laude. Thesis title (in Italian): \"Le reazioni redox nel suolo e il loro significato ambientale\" (supervisor: Franco Ajmone Marsan)."
  },
  {
    "objectID": "Rtools.html",
    "href": "Rtools.html",
    "title": "R codes",
    "section": "",
    "text": "In this page, I aim to provide a collection of R codes and functions that can be valuable to fellow scientists engaged in plant ecology research or related fields.\nYour feedback and contributions are highly encouraged as I do not consider myself an R expert. Please feel free to contact me at gabriele.midolo [at] gmail [dot] com for any question or feedbacks.\n\n1. Quickly retrieve ‘LHS’ traits for the European flora from FloraVeg.EU\nupdated (September 2023)\nFloraVeg.EU is a great source to obtain data for the European vegetation, including habitat information and species traits. Some of these information are fully available at the download section. The data on FloraVeg.EU also contains some information on three main functional traits of the ‘leaf-height-seed’ (LHS) scheme proposed in the famous paper by Westoby (1998), namely specific leaf area (SLA), plant height and seed mass.\n\n\n\n\nScreenshot from the FloraVeg.EU website. For each species, some traits of the LHS scheme might be available. Original link: here.\n\n\nThese data are however not (yet!) available in the download section.\nThe best solution to get such trait data is to get in touch with my former group members in Brno (Czech Republic) (see contacts here). Of course databases like TRY and LEDA are also great option, but requires some times to access the data and process them.\nSometimes one just need traits for a few single species for a quick analysis - (or to make comparisons / check outliers of LHS traits with other databases). In such cases one can easily use R to quickly access such information using the rvest R package (Wickham, 2022). This works pretty good if your plant names already follows the nomenclature from Euro+Med!\nN.B.: Please, cite the FloraVeg.EU when using the data obtained this way. See ‘Data source and citation’ below\nHere is the get.LHS.FloraVegEU function:\nget.LHS.FloraVegEU &lt;- function(species) {\n  require(rvest)\n  \n  url &lt;- paste0('https://floraveg.eu/taxon/overview/',species)\n  webpage &lt;- read_html(URLencode(url))\n    \n  #1. Get plant height\n  str_plant.height &lt;- '#panel_2 .featureDetail:nth-child(1) b'\n  plant.height_html &lt;- html_nodes(webpage, str_plant.height)\n  plant.height &lt;- html_text(plant.height_html)\n  plant.height &lt;- gsub('[^0-9.-]', '', plant.height)\n  if(identical(plant.height, character(0))) {plant.height=NA} else {\n    if(plant.height=='' | plant.height=='-') {plant.height=NA} else {\n      plant.height &lt;- as.numeric(plant.height)\n    }\n    }\n    \n  #2. get specific leaf area\n  str_SLA &lt;- '#panel_3 .align-items-center div'\n  SLA_html &lt;- html_nodes(webpage, str_SLA)\n  SLA &lt;- html_text(SLA_html)\n  if(identical(SLA, character(0))){\n    SLA &lt;- NA\n   } else {\n     for (k in 1:length(SLA)) {\n       i2 &lt;- gsub('mm2', '', SLA[[k]])\n       SLA[[k]] &lt;- gsub('[^0-9.-]', '', i2)\n     }\n     SLA &lt;- suppressWarnings(as.numeric(SLA[!is.na(as.numeric(SLA))]))\n     \n     if (identical(SLA, numeric(0))){\n       SLA &lt;- NA\n     }\n     \n  }\n    \n  #3. get seed mass\n  str_SM &lt;- '#panel_5 b'\n  SM_html &lt;- html_nodes(webpage, str_SM)\n  SM &lt;- html_text(SM_html)\n  SM &lt;- gsub('[^0-9.-]', '', SM)\n  SM &lt;- ifelse(identical(SM, character(0)), NA, SM)\n  SM &lt;- as.numeric(SM)\n    \n  res &lt;- data.frame(\n      plant_height = plant.height,\n      sla = SLA,\n      seed_mass = SM)\n\n  return(res)\n}\nTo use the function just type the name of a single species present in the FloraVeg.EU checklist to obtain the results. For example:\n&gt; get.LHS.FloraVegEU('Bellis perennis')\n  plant_height   sla seed_mass\n1         0.09 32.32      0.12\nNote that species nomencalure must correspond the one in FloraVeg.EU. Mispelled species or species for which data are not available will return either an error or NA values. To work with several species and avoid this issue, one can easily apply a modified version of this function using the ‘possibly’ function of the purrr R package (Wickham, 2023).\n#An example of species list (vector):\nsplis = c('Bellis perennis', #Existing species with full LHS information\n          'Pinus mugo', #Existing species with incomplete LHS information\n          'Pseudobetckea caucasica', #Existing species with no information \n          'Taraxacum midolii' #Mispelled / unexisting species\n          )\n\nlibrary(purrr)\nget.LHS.FloraVegEU_possibly &lt;- possibly(get.LHS.FloraVegEU, \n                                        data.frame(plant_height = NA, sla = NA, seed_mass = NA))\nres &lt;- map(splis, get.LHS.FloraVegEU_possibly) #map the function\nnames(res) &lt;- splis #set species names\nres.df &lt;- do.call(rbind, res) # bind dataset\nThe code returns:\n&gt; res.df\n                        plant_height   sla seed_mass\nBellis perennis                 0.09 32.32      0.12\nPinus mugo                      3.12    NA      6.08\nPseudobetckea caucasica           NA    NA        NA\nTaraxacum midolii                 NA    NA        NA\nReferences:\n\nFloraVeg.EU – Database of European Vegetation, Habitats and Flora. www.floraveg.eu\nWestoby, M. (1998). A leaf-height-seed (LHS) plant ecology strategy scheme. Plant and soil, 199, 213-227. https://doi.org/10.1023/A:1004327224729\nWickham H (2023). purrr: Functional Programming Tools. R package version 1.0.1, https://CRAN.R-project.org/package=purrr.\nWickham H (2022). rvest: Easily Harvest (Scrape) Web Pages. R package version 1.0.3, https://CRAN.R-project.org/package=rvest.\n\nData source and citation for plant functional traits:\n\nAxmanová, I. (2022). Plant height. – www.FloraVeg.EU.\nAxmanová, I. (2022). Specific leaf area. – www.FloraVeg.EU.\nAxmanová, I. (2022). Seed mass. – www.FloraVeg.EU.\nFrench Flora database (baseflor), project of Flore et végétation de la France et du Monde: CATMINAT. Available at http://philippe.julve.pagesperso-orange.fr/catminat.htm [accessed June 2020]\nGarcía-Gutiérrez, T., Jiménez-Alfaro, B., Fernández-Pascual, E., & Müller, J. V. (2018). Functional diversity and ecological requirements of alpine vegetation types in a biogeographical transition zone. Phytocoenologia, 77–89. https://doi.org/10.1127/phyto/2017/0224\nGuarino, R., La Rosa, M. & Pignatti, S. (Eds) (2019). Flora d’Italia, volume 4. Bologna: Edagricole.\nHintze, C., Heydel, F., Hoppe, C., Cunze, S., König, A., & Tackenberg, O. (2013). D3: The Dispersal and Diaspore Database – Baseline data and statistics on seed dispersal. Perspectives in Plant Ecology, Evolution and Systematics, 15(3), 180–192. https://doi.org/10.1016/j.ppees.2013.02.001\nLadouceur, E., Bonomi, C., Bruelheide, H., Klimešová, J., Burrascano, S., Poschlod, P., … Jiménez-Alfaro, B. (2019). The functional trait spectrum of European temperate grasslands. Journal of Vegetation Science, 30(5), 777–788. https://doi.org/10.1111/jvs.12784\nKaplan, Z., Danihelka, J., Chrtek, J. Jr., Kirschner, J., Kubát, K., Štěpánek, J. & Štech, M. (Eds) (2019). Klíč ke květeně České republiky [Key to the flora of the Czech Republic]. Ed. 2. Praha: Academia.\nKleyer, M., Bekker, R. M., Knevel, I. C., Bakker, J. P., Thompson, K., Sonnenschein, M., … Peco, B. (2008). The LEDA Traitbase: A database of life-history traits of the Northwest European flora. Journal of Ecology, 96(6), 1266–1274. https://doi.org/10.1111/j.1365-2745.2008.01430.x\nTavşanoğlu, Ç., & Pausas, J. (2018). A functional trait database for Mediterranean Basin plants. Scientific data, 5, 180135. https://doi.org/10.1038/sdata.2018.135\n\n\n\n2. Plot pairwise complete correlation matrices\nupdated (September 2023)\nIt often happens that a species × trait matrix (or any data set really) is incomplete because of missing trait information for some species. Some species may have some traits, while others don’t. In my experience, this makes difficult to check trait-trait co-variation using common visualization tools in R. Here, I attempted to provide a simple solution by plotting pairwise correlation estimates retaining complete observations (with cor(..., use=\"pairwise.complete.obs\")) for each pair in the lower-right panel and reporting the sample size in the upper-left panel. This way, one can always know how many species report trait data information for each pair and check their correlation value.\nHere are the functions that you can load in your environment to easily produce these plots.\n#Plot correlation matrix with gaps\n\n#1. Accessory functions ####\ngetsamplesize &lt;- function(vec_a, vec_b) {\n  nrow(drop_na(data.frame(vec_a,vec_b)))\n}\nfirstup &lt;- function(x) {\n  substr(x, 1, 1) &lt;- toupper(substr(x, 1, 1))\n  x\n}\nget_lower_tri&lt;-function(cormat){\n  cormat[upper.tri(cormat)] &lt;- NA\n  return(cormat)\n}\nget_upper_tri &lt;- function(cormat){\n  cormat[lower.tri(cormat)]&lt;- NA\n  return(cormat)\n}\n\n#2. load the function\n#N.B. this function requires tidyverse, reshape2, and corrr packages\n\nplot.inc.cor &lt;- function(mat, round.label.digit=2, cor.method='pearson', size.label=4){\n  \n  corm &lt;- cor(mat, method = cor.method, use=\"pairwise.complete.obs\")\n  \n  pcorm &lt;- cor(mat, method = cor.method, use=\"pairwise.complete.obs\") %&gt;%\n    get_lower_tri %&gt;%\n    reshape2::melt()\n  pcorm$value = ifelse(pcorm$Var1 == pcorm$Var2, NA, pcorm$value)\n  psams &lt;- corrr::colpair_map(mat, getsamplesize) %&gt;%\n    as.data.frame %&gt;%\n    tibble::column_to_rownames('term') %&gt;%\n    as.matrix %&gt;%\n    get_upper_tri %&gt;%\n    reshape2::melt() %&gt;%\n    setNames(names(pcorm)) \n  \n  pcorm$value = round(pcorm$value, round.label.digit)\n  # Format the numeric values with two decimal places\n  pcorm$formatted_value &lt;- sprintf(paste0('%.',round.label.digit,'f'), pcorm$value)\n  pcorm$formatted_value &lt;- ifelse(pcorm$formatted_value=='NA',NA,pcorm$formatted_value)\n  \n  p &lt;- ggplot() + \n    geom_tile(data = pcorm, aes(x=Var1, y=Var2, fill=value), color='grey80')+\n    geom_text(data = psams, aes(x=Var1, y=Var2, label = value, alpha=log(value)), color = \"black\", size = size.label) +\n    geom_text(data = pcorm, aes(x=Var1, y=Var2, label = formatted_value), color = \"black\", size = size.label) +\n    scale_fill_gradient2(low = \"#4A6FE3\", mid = \"white\", high = \"#D33F6A\", \n                         midpoint = 0, limit = c(-1,1), space = \"Lab\", \n                         na.value = 'white',\n                         name=paste0(firstup(cor.method),'\\ncorrelation')) +\n    theme_classic() +\n    guides(alpha='none')+\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, color='black'),\n          axis.text.y = element_text(color='black'),\n          axis.title = element_blank(),\n          axis.line = element_blank(),\n          panel.background = element_rect(fill = \"white\",\n                                          colour = \"white\")) +\n    coord_fixed() +\n    geom_abline(slope = 1, intercept = 0, color='grey80') \n  return(p)\n}\nSimulate some data and visualize the output with the plot.inc.cor function:\nset.seed(9)\n\nlibrary(tidyverse); library(reshape2); library(corrr)\n\n# Number of rows and columns in the dataframe\nnum_species &lt;- 100\nnum_traits &lt;- 7\n\n# Generate random data with NAs\ndmatrix &lt;- matrix(runif(num_species * num_traits), nrow = num_species)\n\n# Randomly replace 25% of values with NA\ndmatrix[sample(length(dmatrix), length(dmatrix)*0.25)] &lt;- NA\n\n# Convert the matrix to a dataframe\ndmatrix &lt;- as.data.frame(dmatrix)\nnames(dmatrix) = paste0('Trait',1:ncol(dmatrix))\n\nplot.inc.cor(dmatrix, cor.method='pearson', round.label.digit=2, size.label=3)\n\n\n\nExample of output obtained, using default options. Upper left panel displays the number of observations without NAs (complete cases) for each pair; bottom right panel shows their correlation coefficient (default is ‘pearson’).\n\n\n\n\n3. Calculate range elongation\nupdated (April 2024)\nUPDATE! You can download the get_RLI function here. For additional details, please refer to the tutorial below and to the main publication available online: Midolo (2024) in Global Ecology and Biogeography.\nSpecies range shape refers to how a species’ distribution differs from a perfectly symmetrical or isotropic pattern expected under neutral range dynamics. Some researchers have indeed proposed estimating shape elongation as a significant biogeographical species attribute (Rapoport, 1982; Brown et al., 1996; Pigot et al., 2010; Baselga et al., 2012; Castro-Insua et al., 2018).\nHere I share an R code (= the get_RLI function) to calculate a metric similar to what described as the Range Linearity Index (RLI) by Pigot et al. (2010). The RLI is a dimensionless measure calculated as RLI = l2 / a, where l represents the maximum linear dimension, and a represents the area of the polygon. To compute the l metric, we will determine the longest length among the shortest paths connecting all possible combinations of the westernmost, easternmost, northernmost, and southernmost geographical points at the extremes of each polygon. As a result, the RLI offers an intuitive way to quantify shape elongation, analogous to the long axis to width ratio (Graves 1988; Pigot et al. 2010). For example, an RLI value of 2 indicates a shape that is twice as long as it is wide.\n\n\n\nWorkflow to calculate range shape (= range elongation calculated as the Range Linearity Index, RLI) in the get_RLI function. The figure illustrates a schematic example for the native range of the wych elm (Ulmus glabra) (data source: Caudullo et al. 2017). Panel a) display the whole range of the species. Panel b) shows the largest range portions (= fragments) selected for RLI calculation (the biggest range fragments are used by default based on the rationale these are more important in defyining the whole range shape). RLI for species w is calculated as the average of RLI values of each range fragment (RLIi). RLI is the dimensioness ratio between squared length (l2) and area of the polygon, where l is the longest path across the shortest distance between the geographical points located at the extremes of each polygon (line in red; panel c). Maps are displayed with UTM EPSG:32633 projection.\n\n\nHere is the code for the get_RLI function:\nget_RLI &lt;- function(range, # a multi polygons sf object of the species range\n                    directional.constraint='none', # constraint the shortest path? default is none, use 'lon' or 'lat' to constrain the paths along longitude or latitude\n                    fragment.inclusivity = 0.1, # the lowest this value, the highest is the proportion of fragments considered for range calculation. Lowest fragments \n                    columns.and.rows=100, # number of col and rows of the raster for each range fragment, increasing this number makes a raster with finer resolution, increasing considerably the amount of time!\n                    direction = 8, # the 'directions' argument of the gdistance::transition() function. Values of 4, 8 and 16 are reccomended\n                    graphical = T, # if T, plot the range with line objects (paths) used for RLI estimation\n                    col.bl='red', # if graphical == T, the color of the final paths used for RLI estimation in the graph\n                    very.graphical = F) # plot each fragment under examination and its candidate paths\n  {\n  st=Sys.time()\n  \n  UTM32 = '+proj=utm +zone=32 +datum=WGS84 +units=m +no_defs'\n  orirange &lt;- st_sf(range) # trasform to sf object\n  st_geometry(orirange) &lt;- 'geometry'\n  orirange &lt;- st_transform(orirange, UTM32) #reproject to UTM zone 32\n  rprp &lt;- orirange %&gt;% st_cast('POLYGON') # cast to POLYGON (= separating fragments)\n  rprp$area &lt;- as.numeric(st_area(rprp$geometry)) # calculate area for each fragment in m^2\n  rprp = rprp %&gt;% arrange(desc(area))\n  rprp$adif &lt;- rprp$area/max(rprp$area) # proportional area difference with the nmain range\n  #exclude too small fragments:\n  rprpo = rprp\n  rprp = rprp[rprp$adif&gt;=fragment.inclusivity,]\n  rprp$id = 1:nrow(rprp)\n  \n  print(paste0('Assessing ',nrow(rprp),' range fragments out of ', nrow(rprpo)))\n  \n  sentieri &lt;- list() #list where to store fragments' RLI stats\n  for (frag in 1:nrow(rprp)) {\n    \n    st.i &lt;- Sys.time()\n    \n    polyi &lt;- rprp[frag,]\n    #apply Behrman transofmration, lon_0 set depending upon longitudinal extension (correcting for distortion)\n    polyi = st_transform(polyi, crs = '+proj=cea +lon_0=0 +lat_ts=30 +x_0=0 +y_0=0 +datum=WGS84 +ellps=WGS84 +units=m +no_defs')\n    if(round(abs(min(st_coordinates(polyi)[,1]))) == round(abs(max(st_coordinates(polyi)[,1])))){\n      polyi = st_transform(rprp[frag,], crs = '+proj=cea +lon_0=10 +lat_ts=30 +x_0=0 +y_0=0 +datum=WGS84 +ellps=WGS84 +units=m +no_defs')\n    }\n    \n    crs.polyi &lt;- crs(as_Spatial(polyi))\n    \n    poly.grid &lt;- st_make_grid(polyi, n=rep(columns.and.rows,2)) %&gt;%\n      st_sf() %&gt;%\n      mutate(row.id = row_number())\n    \n    defaultW &lt;- getOption(\"warn\")\n    \n    #1. define the area where the line can pass through (= 'playground')\n    options(warn = -1)\n    playground &lt;- poly.grid %&gt;%\n      left_join(\n        as.data.frame(st_intersects(poly.grid,polyi))%&gt;%rename(value = col.id),'row.id'\n      ) %&gt;% dplyr::select(-row.id) %&gt;%\n      st_cast('POINT') %&gt;%\n      as_Spatial() %&gt;% \n      as.data.frame() %&gt;% \n      setNames(c('z','x','y')) %&gt;% \n      dplyr::select(x,y,z) %&gt;%\n      rasterFromXYZ(crs = crs.polyi)\n    options(warn = defaultW)\n    \n    #plot:\n    if(very.graphical) {plot(playground, col='grey',main=paste0('fragment n. ',frag),legend=F)}\n    \n    \n    #2. define the start/arrival point cells (= 'rallypoints')\n    coord &lt;- st_coordinates(polyi) %&gt;% as.data.frame()\n    \n    options(warn = -1)\n    rallypoints &lt;- list(\n      southernmost = coord[which.min(coord[, \"Y\"]), ],\n      northernmost = coord[which.max(coord[, \"Y\"]), ],\n      easternmost = coord[which.max(coord[, \"X\"]), ],\n      westernmost = coord[which.min(coord[, \"X\"]), ]\n    ) %&gt;% \n      bind_rows(.id='flag') %&gt;%\n      st_as_sf(coords=c(\"X\",\"Y\"), crs = st_crs(polyi)) %&gt;%\n      dplyr::select(flag,geometry)\n    \n    raster.cooord &lt;- poly.grid %&gt;%\n      left_join(\n        as.data.frame(st_intersects(poly.grid,rallypoints))%&gt;%rename(value = col.id),'row.id'\n      ) %&gt;% \n      filter(!is.na(value)) %&gt;%\n      dplyr::select(-row.id) %&gt;%\n      st_centroid() %&gt;%\n      st_coordinates %&gt;%\n      as.data.frame()\n    \n    rallyrasters &lt;- list(\n      southernmost = raster.cooord[which.min(raster.cooord[, \"Y\"]), ],\n      northernmost = raster.cooord[which.max(raster.cooord[, \"Y\"]), ],\n      easternmost = raster.cooord[which.max(raster.cooord[, \"X\"]), ],\n      westernmost = raster.cooord[which.min(raster.cooord[, \"X\"]), ]\n    ) %&gt;% \n      bind_rows(.id='flag')\n    \n    options(warn = defaultW)\n    \n    if(directional.constraint == 'lon') {\n      rallyrasters &lt;- rallyrasters %&gt;% filter(flag == 'easternmost' | flag == 'westernmost')\n    }\n    \n    if(directional.constraint == 'lat') {\n      rallyrasters &lt;- rallyrasters %&gt;% filter(flag == 'southernmost' | flag == 'northernmost')\n    }\n    \n    rallyrasters_spatial &lt;- rallyrasters %&gt;% st_as_sf(coords = c('X','Y'), crs=crs.polyi)\n    \n    #3. force misplaced points towards raster, if needed\n    check.allocation &lt;- raster::extract(playground,rallyrasters_spatial)\n    if (any(is.na(check.allocation))){\n      badpoints &lt;- rallyrasters[is.na(check.allocation),] %&gt;% st_as_sf(coords=c('X','Y'))\n      for (k in 1:nrow(badpoints)) {\n        vvo &lt;- rasterToPoints(playground) %&gt;% as.data.frame() %&gt;% filter(!is.na(z))\n        vv &lt;- st_as_sf(vvo,coords=c('x','y'))\n        vv$dist &lt;- st_distance(vv$geometry, badpoints[k,]$geometry)\n        new.alloc &lt;- vvo[which(vv$dist == min(vv$dist)),] %&gt;% sample_n(1)\n        rallyrasters[is.na(check.allocation),][,2:3][k,]$X = new.alloc$x\n        rallyrasters[is.na(check.allocation),][,2:3][k,]$Y = new.alloc$y\n      }}\n    \n    rallyrasters_spatial &lt;- rallyrasters %&gt;% st_as_sf(coords = c('X','Y'), crs=crs.polyi)\n    \n    if(very.graphical) {\n      rallyrasters_spatial$flagcol = c(rep('grey30',4))[1:nrow(rallyrasters)]\n      plot(rallyrasters_spatial, col=rallyrasters_spatial$flagcol,add=T,legend=F, pch=16)\n    }\n    \n    thepoints2test &lt;- rallyrasters[,-1]\n    thepoints2test$id &lt;- 1:nrow(thepoints2test)\n    \n    egrid_unique.combs &lt;- as.data.frame(t(combn(thepoints2test$id,2))) %&gt;% \n      bind_rows(data.frame(V1=thepoints2test$id,V2=thepoints2test$id)) %&gt;% \n      setNames(c('n1','n2')) #a non-redundant version of expand_grid\n    \n    egrid &lt;- cbind(\n      expand_grid(n1=thepoints2test$id, n2=thepoints2test$id),\n      expand_grid(d1=cbind(thepoints2test$X,thepoints2test$Y), d2=cbind(thepoints2test$X,thepoints2test$Y))\n    ) %&gt;% \n      semi_join(egrid_unique.combs, by=c('n1','n2'))%&gt;% #a non-redundant tibble of pairwise combinations\n      filter(n1!=n2)\n    egrid &lt;- egrid[,-c(1,2)]\n    \n    tr1 &lt;- gdistance::transition(playground, transitionFunction=mean, directions=direction)\n    tr1 &lt;- gdistance::geoCorrection(tr1,'c')\n    \n    #start detecting the possible paths...\n    if(very.graphical) {vcol &lt;- viridis::viridis(nrow(egrid),direction = 1)}\n    linee &lt;- list()\n    lunghezze &lt;- vector()\n    for (l in 1:nrow(egrid)) {\n      linee[[l]] &lt;- gdistance::shortestPath(tr1, \n                                    as.numeric(egrid[l,1]),\n                                    as.numeric(egrid[l,2]),\n                                    output=\"SpatialLines\") %&gt;%\n        st_as_sf() %&gt;%\n        st_set_crs(tr1@srs) %&gt;%\n        st_transform(st_crs(orirange))\n      \n      if(very.graphical){plot(linee[[l]] %&gt;% st_transform(crs(playground)), add=T, col=vcol[l],lwd=2, lty=1)}\n      lunghezze[l] &lt;- as.numeric(st_length(linee[[l]]))\n    }\n    \n    I.stat &lt;- max(lunghezze)\n    a &lt;- polyi$area\n    \n    which.best.line &lt;- c(which(lunghezze == I.stat))\n    bl.id &lt;- ifelse(length(which.best.line) == 1, which.best.line, sample(which.best.line,1))\n    bl &lt;- linee[[bl.id]]\n\n    sentieri[[frag]] &lt;- list(\n      best.path = bl,\n      df = data.frame(fragment=frag, I=I.stat, A=a, RLI = as.numeric(I.stat)^2/a)\n    )\n    \n    cati = str_pad(frag,nchar(nrow(rprp)),side='left',pad='0')\n    et.i = Sys.time() - st.i\n    message('Fragment ',cati,' time: ',paste(round(et.i,2)),' ',attr(et.i,'units'))\n  }\n  \n  \n  out = list(\n    RLI.vals = bind_rows(purrr::map(sentieri, function(x){x$df})),\n    RLI.lins = bind_rows(purrr::map(sentieri, function(x){st_sf(x$best.path)}))\n  )\n  \n  if(graphical){\n    plot(as_Spatial(orirange), col='black', border=NA)\n    plot(as_Spatial(rprp),col='darkolivegreen3',add=T,border=NA)\n    plot(out$RLI.lins, col=col.bl, add=T, lwd=3)\n  }\n  \n  et=Sys.time()-st\n  message(paste0('... DONE! Total elapsed time: ',paste(round(et,2)),' ',attr(et,'units')))\n  return(out)\n}\nHere is a simple tutorial. In this example, we calculate RLI for Taurus fir (Abies cilicica), a tree species growing in Lebanon and Turkey. The original native range was downloaded here (source: Caudullo et al. 2017).\n#1. prepare the data\n\n#the function depends upon the following R packages:\n\nlibrary(tidyverse); library(sf); library(raster); library(gdistance)\n\n#define coordinates of the simplifed range of Taurus fir\n\ncoords &lt;- \"MULTIPOLYGON (((30.70949 37.44737, 30.47034 37.32006, 30.52049 37.20553, 30.71815 37.2789, 30.70949 37.44737)), ((31.11012 37.42078, 30.97528 37.4679, 30.88733 37.36318, 30.93263 37.24811, 31.11012 37.42078)), ((36.46468 37.03979, 36.31841 36.89317, 36.33939 36.7773, 36.49918 36.8471, 36.46468 37.03979)), ((36.6707 37.29474, 36.66847 37.51403, 36.59149 37.58607, 36.59808 37.87782, 36.73713 37.93399, 36.84522 37.90433, 36.96676 37.9688, 36.96026 38.04769, 36.70301 38.12471, 36.67512 38.18166, 36.54407 38.27753, 36.43666 38.13201, 36.15473 38.10206, 36.21972 38.26696, 36.29701 38.28576, 36.39462 38.32924, 36.09729 38.36283, 35.89325 38.15608, 35.73671 38.09842, 35.69503 37.97337, 35.24333 37.68169, 35.04145 37.78691, 34.84408 37.54285, 34.47599 37.51281, 34.39836 37.40821, 34.6797 37.42135, 34.68839 37.31277, 34.55881 37.28519, 34.27545 37.15911, 34.18091 36.91732, 33.99108 36.94332, 33.80763 36.56233, 34.02319 36.61594, 34.19481 36.74509, 34.34339 36.97006, 34.59568 37.03146, 34.63063 37.1486, 34.94324 37.24132, 34.98489 37.32413, 35.56452 37.59327, 35.79142 37.8377, 35.8945 38.05866, 35.97055 37.94501, 35.95044 37.6577, 36.13366 37.56702, 36.30933 37.58298, 36.43974 37.49443, 36.46066 37.35781, 36.6707 37.29474)), ((36.23528 34.52347, 35.98332 34.34524, 35.96573 34.2879, 36.28164 34.46973, 36.23528 34.52347)), ((31.27839 37.37006, 31.34101 37.04838, 31.52389 36.88489, 31.95332 36.8085, 32.09129 36.57597, 32.23787 36.55928, 32.48722 36.16406, 33.13701 36.23291, 33.17804 36.38689, 33.09851 36.40655, 33.05761 36.52104, 32.96027 36.36613, 32.73956 36.37612, 32.63873 36.26141, 32.5014 36.32853, 32.48627 36.75422, 32.34106 36.76603, 32.26759 36.84551, 32.28035 36.75343, 32.11068 36.73524, 32.08518 36.86551, 31.86951 36.9232, 31.95336 37.16447, 31.70671 37.38032, 31.4169 37.29067, 31.27839 37.37006)), ((32.93654 36.86382, 32.99047 36.65178, 33.08621 36.62425, 33.04779 36.8336, 32.93654 36.86382)))\"\n\n#coordinates to multipolygon sf object:\n\nrange &lt;- st_as_sfc(coords, crs='+proj=longlat +datum=WGS84 +no_defs')\n\n#quickly visualise the geometry in a map (optional, requires mapview):\n\nmapview::mapview(range)\n\n\n\nSimplified polygon shape for Taurus fir (Abies cilicica) using mapview\n\n\nNow, let’s run the get_RLI function, with default options:\n#run the function with default options:\nres &lt;- get_RLI(range)\n[1] \"Assessing 2 range fragments out of 7\" \nFragment 1 time: 2.82 secs \nFragment 2 time: 3.04 secs \n... DONE! Total elapsed time: 5.94 secs \n\n\n\nGraphical output obtained from the function at the end of RLI calculation (set graphical=FALSE to supress the plotting). By default the function displays the different fragments composing species ranges and the longest paths (in red). These are only calculated and drawn for the range fragments considered in the analysis (in green; unutilized range fragment are displayed in black).\n\n\nLet’s inspect the results:\nres$RLI.vals # values of RLI for each fragment, units are in m\n  fragment        I           A      RLI\n1        1 248601.8  5779445898 10.69356\n2        2 374410.0 12863135567 10.89803\n\nweighted.mean(res$RLI.vals$RLI, w = res$RLI.vals$A) # obtain RLI, weighted by the size of each fragment\n10.83464\n\nres$RLI.lins # LINESTRING geometries (the drawn lines)\nWe calculated the species-level RLI, using the average of the RLI of each fragment weighted by its area A. We conclude that range elongation of Abies cilicica is quite pronounced (RLI = 10.8), meaning it is almost about eleven times long as it is wide.\nWe can allow the function to return some plot displaying all possible shorthests path considered for each range fragment included in the analysis by setting the parameter very.graphical=TRUE.\n# show the intermediate steps of calculation for each path\nget_RLI(range, very.graphical = T, graphical = F) \n\n\n\nAll possible paths considered in each of the fragments assessed. Across each of the four path, the longest one is selected to calculate l by default. N.B. the geographic coordinates on the xy follow the Behrman transformation for estimation of geographic extremes.\n\n\nIn some systems, one may want to focus exclusively upon the elongation along either longitude or latitude. For example, given the south-to-north distribution of Andean montane forests, one might be interested in knowing the elongation of a species along latitude (e.g. see Graves 1988). On the other hand, range elongation along longitiude might be a good indicator for e.g. plant species constrained to coastal lines in the Mediterranean. In this context, we can simply force the function to consider only northermost-to-southernmost points with directional.constraint = 'lat' or westernmost-to-easternmost points with directional.constraint = 'lon' (default is directional.constraint = 'none')\n#constraint shortest path only latitude or longitude paths\nget_RLI(range, directional.constraint = 'lat', col.bl = 'red')\nget_RLI(range, directional.constraint = 'lon', col.bl = 'blue')\n\n\n\nThe visual output obtained when directional.constraint parameter is modified accordingly (edited figures)\n\n\nFinally, one may also consider more fragments for RLI calculation, as in principle there is no reason to exclude smallest fragments. However, I) range polygons could be much more complex and bigger than what we are using here, resulting into non-negligible computation times for this function, and II) the RLI calculation weighted by area makes nearly useless to consider all possible tiny fragments composing a species range. Anyway, we can modify the fragment.inclusivity parameter to do so (default here is setted to 0.1). This is a threshold value. It allows the inclusion of fragments by calculating the ratio between the area of each fragment to the area of the fragment with the largest area. Only fragments with values greater or equal to fragment.inclusivity are included for RLI calculation. Thus, the lowest this value, the highest is the proportion of fragments considered for range calculation. Set fragment.inclusivity=0 if you want all fragments to be considered for RLI estimation.\n#decrease inclusivity treshold for range fragments (i.e., consider an increasing number of smaller fragments for RLI estimation) \nres2 &lt;- get_RLI(range, fragment.inclusivity = 0.02) # default is 0.1\n\n\n\n\n\n&gt; res2$RLI.vals # we now included more fragments\n  fragment         I           A       RLI\n1        1  34405.63   304506996  3.887422\n2        2  34215.45   364252009  3.213975\n3        3 248601.78  5779445898 10.693559\n4        4 374409.97 12863135567 10.898029\n\n&gt; weighted.mean(res2$RLI.vals$RLI, w = res2$RLI.vals$A) #but they matter less in overall RLI calculation\n[1] 10.58135\nYou can see we have now two smaller fragments considered for RLI calculation. Yet, these new smaller fragments weight less in the final average, and thus they do not affect the final RLI calculation that much. Again, this follow the assumption that smaller ranges matter less for overall range shape estimation.\nReferences\n\nBaselga, A., Lobo, J. M., Svenning, J. C., & Araújo, M. B. (2012). Global patterns in the shape of species geographical ranges reveal range determinants. Journal of Biogeography, 39(4), 760–771. ​\nBrown, J. H., Stevens, G. C., & Kaufman, D. M. (1996). The Geographic Range: Size, Shape, Boundaries, and Internal Structure. Annual Review of Ecology and Systematics, 27(1), 597–623. \nCastro‐Insua, A., Gómez‐Rodríguez, C., Svenning, J. C., & Baselga, A. (2018). A new macroecological pattern: The latitudinal gradient in species range shape. Global Ecology and Biogeography, 27(3), 357-367.\n​Caudullo, G., Welk, E., & San-Miguel-Ayanz, J. (2017). Chorological maps for the main European woody species. Data in Brief, 12, 662–666.\n​Graves, G. R. (1988). Linearity of Geographic Range and Its Possible Effect on the Population Structure of Andean Birds. The Auk, 105(1), 47–52. \n​Pigot, A. L., Owens, I. P. F., & Orme, C. D. L. (2010). The environmental limits to geographic range expansion in birds. Ecology Letters, 13(6), 705–715. \nRapoport, E. H. (1982). Aerography: Geographical Strategies of Species. Pergamon Press, Oxford UK."
  },
  {
    "objectID": "Rtools.html#a-simple-r-function-to-quickly-obtain-lhs-traits-from-floraveg.eu",
    "href": "Rtools.html#a-simple-r-function-to-quickly-obtain-lhs-traits-from-floraveg.eu",
    "title": "simple R tools",
    "section": "A simple R function to quickly obtain LHS traits from FloraVeg.EU",
    "text": "A simple R function to quickly obtain LHS traits from FloraVeg.EU"
  },
  {
    "objectID": "Rtools.html#a-simple-r-function-to-quickly-obtain-lhs-traits-for-the-european-flora",
    "href": "Rtools.html#a-simple-r-function-to-quickly-obtain-lhs-traits-for-the-european-flora",
    "title": "simple R tools",
    "section": "A simple R function to quickly obtain LHS traits for the European flora",
    "text": "A simple R function to quickly obtain LHS traits for the European flora\nThe FloraVeg.EU website is a great source to obtain data for the European vegetation, including habitat information and species traits. Some of these information are available at the download section. The data on FloraVeg.EU also contains some information on three main functional traits of the LHS scheme proposed in the famous paper by Westoby (1998), namely specific leaf area (SLA), plant height and seed mass - but they are not yet available on the website, as they can be obtained using . These data are however obtained\nBelow is a simple R function to extract these data online. Please, cite the FloraVeg.EU when using the references listed below.\n\n\nData source and citation:\n\nAxmanová, I. (2022). Plant height. – www.FloraVeg.EU.\nAxmanová, I. (2022). Specific leaf area. – www.FloraVeg.EU.\nAxmanová, I. (2022). Seed mass. – www.FloraVeg.EU.\nFloraVeg.EU – Database of European Vegetation, Habitats and Flora. www.floraveg.eu\nFrench Flora database (baseflor), project of Flore et végétation de la France et du Monde: CATMINAT. Available at http://philippe.julve.pagesperso-orange.fr/catminat.htm [accessed June 2020]\nGarcía-Gutiérrez, T., Jiménez-Alfaro, B., Fernández-Pascual, E., & Müller, J. V. (2018). Functional diversity and ecological requirements of alpine vegetation types in a biogeographical transition zone. Phytocoenologia, 77–89. https://doi.org/10.1127/phyto/2017/0224\nGuarino, R., La Rosa, M. & Pignatti, S. (Eds) (2019). Flora d’Italia, volume 4. Bologna: Edagricole.\nHintze, C., Heydel, F., Hoppe, C., Cunze, S., König, A., & Tackenberg, O. (2013). D3: The Dispersal and Diaspore Database – Baseline data and statistics on seed dispersal. Perspectives in Plant Ecology, Evolution and Systematics, 15(3), 180–192. https://doi.org/10.1016/j.ppees.2013.02.001\nLadouceur, E., Bonomi, C., Bruelheide, H., Klimešová, J., Burrascano, S., Poschlod, P., … Jiménez-Alfaro, B. (2019). The functional trait spectrum of European temperate grasslands. Journal of Vegetation Science, 30(5), 777–788. https://doi.org/10.1111/jvs.12784\nKaplan, Z., Danihelka, J., Chrtek, J. Jr., Kirschner, J., Kubát, K., Štěpánek, J. & Štech, M. (Eds) (2019). Klíč ke květeně České republiky [Key to the flora of the Czech Republic]. Ed. 2. Praha: Academia.\nKleyer, M., Bekker, R. M., Knevel, I. C., Bakker, J. P., Thompson, K., Sonnenschein, M., … Peco, B. (2008). The LEDA Traitbase: A database of life-history traits of the Northwest European flora. Journal of Ecology, 96(6), 1266–1274. https://doi.org/10.1111/j.1365-2745.2008.01430.x\nTavşanoğlu, Ç., & Pausas, J. (2018). A functional trait database for Mediterranean Basin plants. Scientific data, 5, 180135. https://doi.org/10.1038/sdata.2018.135"
  },
  {
    "objectID": "Rtools.html#quickly-obtain-lhs-traits-for-the-european-flora-in-r",
    "href": "Rtools.html#quickly-obtain-lhs-traits-for-the-european-flora-in-r",
    "title": "simple R tools",
    "section": "Quickly obtain LHS traits for the European flora in R",
    "text": "Quickly obtain LHS traits for the European flora in R\nThe FloraVeg.EU website is a great source to obtain data for the European vegetation, including habitat information and species traits. Some of these information are available at the download section. The data on FloraVeg.EU also contains some information on three main functional traits of the LHS scheme proposed in the famous paper by Westoby (1998), namely specific leaf area (SLA), plant height and seed mass - but they are not yet available on the website, as they can be obtained using .\nThese data are however not (yet!) available in the download section.\nThe best solution to get such trait data is to get in touch with my former colleagues in Brno (Czech Republic) (see contacts here) (of course databases like TRY and LEDA are also great option). But sometimes I just need traits for a few single species for quick analysis - (or to make comparisons / check outliers of LHS traits with other databases). In such cases one can easily use this function to get traits, using the rvest R package (Wickham, 2022).\n\nN.B.: Please, cite the FloraVeg.EU when using the references listed below!\nReferences:\n\nFloraVeg.EU – Database of European Vegetation, Habitats and Flora. www.floraveg.eu\nWestoby, M. (1998). A leaf-height-seed (LHS) plant ecology strategy scheme. Plant and soil, 199, 213-227. https://doi.org/10.1023/A:1004327224729\nWickham H (2022). rvest: Easily Harvest (Scrape) Web Pages. R package version 1.0.3, https://CRAN.R-project.org/package=rvest.\n\nData source and citation:\n\nAxmanová, I. (2022). Plant height. – www.FloraVeg.EU.\nAxmanová, I. (2022). Specific leaf area. – www.FloraVeg.EU.\nAxmanová, I. (2022). Seed mass. – www.FloraVeg.EU.\nFrench Flora database (baseflor), project of Flore et végétation de la France et du Monde: CATMINAT. Available at http://philippe.julve.pagesperso-orange.fr/catminat.htm [accessed June 2020]\nGarcía-Gutiérrez, T., Jiménez-Alfaro, B., Fernández-Pascual, E., & Müller, J. V. (2018). Functional diversity and ecological requirements of alpine vegetation types in a biogeographical transition zone. Phytocoenologia, 77–89. https://doi.org/10.1127/phyto/2017/0224\nGuarino, R., La Rosa, M. & Pignatti, S. (Eds) (2019). Flora d’Italia, volume 4. Bologna: Edagricole.\nHintze, C., Heydel, F., Hoppe, C., Cunze, S., König, A., & Tackenberg, O. (2013). D3: The Dispersal and Diaspore Database – Baseline data and statistics on seed dispersal. Perspectives in Plant Ecology, Evolution and Systematics, 15(3), 180–192. https://doi.org/10.1016/j.ppees.2013.02.001\nLadouceur, E., Bonomi, C., Bruelheide, H., Klimešová, J., Burrascano, S., Poschlod, P., … Jiménez-Alfaro, B. (2019). The functional trait spectrum of European temperate grasslands. Journal of Vegetation Science, 30(5), 777–788. https://doi.org/10.1111/jvs.12784\nKaplan, Z., Danihelka, J., Chrtek, J. Jr., Kirschner, J., Kubát, K., Štěpánek, J. & Štech, M. (Eds) (2019). Klíč ke květeně České republiky [Key to the flora of the Czech Republic]. Ed. 2. Praha: Academia.\nKleyer, M., Bekker, R. M., Knevel, I. C., Bakker, J. P., Thompson, K., Sonnenschein, M., … Peco, B. (2008). The LEDA Traitbase: A database of life-history traits of the Northwest European flora. Journal of Ecology, 96(6), 1266–1274. https://doi.org/10.1111/j.1365-2745.2008.01430.x\nTavşanoğlu, Ç., & Pausas, J. (2018). A functional trait database for Mediterranean Basin plants. Scientific data, 5, 180135. https://doi.org/10.1038/sdata.2018.135"
  },
  {
    "objectID": "art.html",
    "href": "art.html",
    "title": "Drawings and Paintings",
    "section": "",
    "text": "My art has moved somewhere else…"
  },
  {
    "objectID": "art.html#larger-header",
    "href": "art.html#larger-header",
    "title": "drawing and paintings",
    "section": "",
    "text": "Watercolor and pen on paper (21 × 29.7 cm)"
  },
  {
    "objectID": "art.html#mocking-of-christ",
    "href": "art.html#mocking-of-christ",
    "title": "drawing and paintings",
    "section": "",
    "text": "Mocking of Christ (Cristo deriso)\nWatercolor and pen on paper (21 × 29.7 cm)"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Reconstructing 25 years of house price dynamics across the United States without time series data\n\n\n\n\n\n\n\nmachine learning\n\n\nGIS\n\n\n\n\nA ML-driven geostatistical interpolation to predict 25-year price changes of houses across the United States without temporal replication\n\n\n\n\n\n\nApr 26, 2025\n\n\n\n\n\n\n  \n\n\n\n\nMeasuring species range elongation\n\n\n\n\n\n\n\necology\n\n\nGIS\n\n\n\n\nAn R function to calculate the Range Linearity Index (RLI) by Pigot et al. (2010)\n\n\n\n\n\n\nApr 18, 2024\n\n\n\n\n\n\n  \n\n\n\n\nObtain functional traits for European plants\n\n\n\n\n\n\n\ndata mining\n\n\necology\n\n\n\n\nHere I provide a function in R to mine ‘LHS’ traits (i.e., specific leaf area, plant height, and seed mass) from FloraVeg.EU\n\n\n\n\n\n\nOct 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nSimple pairwise visualizations for incomplete datasets\n\n\n\n\n\n\n\ndata visualization\n\n\necology\n\n\n\n\nAn R code to visualize correlations using complete observations for each pairwise combination\n\n\n\n\n\n\nSep 9, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lhs_traints.html",
    "href": "lhs_traints.html",
    "title": "Gabriele Midolo",
    "section": "",
    "text": "1. Quickly retrieve ‘LHS’ traits for the European flora from FloraVeg.EU\nupdated (September 2023)\nFloraVeg.EU is a great source to obtain data for the European vegetation, including habitat information and species traits. Some of these information are fully available at the download section. The data on FloraVeg.EU also contains some information on three main functional traits of the ‘leaf-height-seed’ (LHS) scheme proposed in the famous paper by Westoby (1998), namely specific leaf area (SLA), plant height and seed mass.\n\n\n\n\nScreenshot from the FloraVeg.EU website. For each species, some traits of the LHS scheme might be available. Original link: here.\n\n\nThese data are however not (yet!) available in the download section.\nThe best solution to get such trait data is to get in touch with my former group members in Brno (Czech Republic) (see contacts here). Of course databases like TRY and LEDA are also great option, but requires some times to access the data and process them.\nSometimes one just need traits for a few single species for a quick analysis - (or to make comparisons / check outliers of LHS traits with other databases). In such cases one can easily use R to quickly access such information using the rvest R package (Wickham, 2022). This works pretty good if your plant names already follows the nomenclature from Euro+Med!\nN.B.: Please, cite the FloraVeg.EU when using the data obtained this way. See ‘Data source and citation’ below\nHere is the get.LHS.FloraVegEU function:\nget.LHS.FloraVegEU &lt;- function(species) {\n  require(rvest)\n  \n  url &lt;- paste0('https://floraveg.eu/taxon/overview/',species)\n  webpage &lt;- read_html(URLencode(url))\n    \n  #1. Get plant height\n  str_plant.height &lt;- '#panel_2 .featureDetail:nth-child(1) b'\n  plant.height_html &lt;- html_nodes(webpage, str_plant.height)\n  plant.height &lt;- html_text(plant.height_html)\n  plant.height &lt;- gsub('[^0-9.-]', '', plant.height)\n  if(identical(plant.height, character(0))) {plant.height=NA} else {\n    if(plant.height=='' | plant.height=='-') {plant.height=NA} else {\n      plant.height &lt;- as.numeric(plant.height)\n    }\n    }\n    \n  #2. get specific leaf area\n  str_SLA &lt;- '#panel_3 .align-items-center div'\n  SLA_html &lt;- html_nodes(webpage, str_SLA)\n  SLA &lt;- html_text(SLA_html)\n  if(identical(SLA, character(0))){\n    SLA &lt;- NA\n   } else {\n     for (k in 1:length(SLA)) {\n       i2 &lt;- gsub('mm2', '', SLA[[k]])\n       SLA[[k]] &lt;- gsub('[^0-9.-]', '', i2)\n     }\n     SLA &lt;- suppressWarnings(as.numeric(SLA[!is.na(as.numeric(SLA))]))\n     \n     if (identical(SLA, numeric(0))){\n       SLA &lt;- NA\n     }\n     \n  }\n    \n  #3. get seed mass\n  str_SM &lt;- '#panel_5 b'\n  SM_html &lt;- html_nodes(webpage, str_SM)\n  SM &lt;- html_text(SM_html)\n  SM &lt;- gsub('[^0-9.-]', '', SM)\n  SM &lt;- ifelse(identical(SM, character(0)), NA, SM)\n  SM &lt;- as.numeric(SM)\n    \n  res &lt;- data.frame(\n      plant_height = plant.height,\n      sla = SLA,\n      seed_mass = SM)\n\n  return(res)\n}\nTo use the function just type the name of a single species present in the FloraVeg.EU checklist to obtain the results. For example:\n&gt; get.LHS.FloraVegEU('Bellis perennis')\n  plant_height   sla seed_mass\n1         0.09 32.32      0.12\nNote that species nomencalure must correspond the one in FloraVeg.EU. Mispelled species or species for which data are not available will return either an error or NA values. To work with several species and avoid this issue, one can easily apply a modified version of this function using the ‘possibly’ function of the purrr R package (Wickham, 2023).\n#An example of species list (vector):\nsplis = c('Bellis perennis', #Existing species with full LHS information\n          'Pinus mugo', #Existing species with incomplete LHS information\n          'Pseudobetckea caucasica', #Existing species with no information \n          'Taraxacum midolii' #Mispelled / unexisting species\n          )\n\nlibrary(purrr)\nget.LHS.FloraVegEU_possibly &lt;- possibly(get.LHS.FloraVegEU, \n                                        data.frame(plant_height = NA, sla = NA, seed_mass = NA))\nres &lt;- map(splis, get.LHS.FloraVegEU_possibly) #map the function\nnames(res) &lt;- splis #set species names\nres.df &lt;- do.call(rbind, res) # bind dataset\nThe code returns:\n&gt; res.df\n                        plant_height   sla seed_mass\nBellis perennis                 0.09 32.32      0.12\nPinus mugo                      3.12    NA      6.08\nPseudobetckea caucasica           NA    NA        NA\nTaraxacum midolii                 NA    NA        NA\nReferences:\n\nFloraVeg.EU – Database of European Vegetation, Habitats and Flora. www.floraveg.eu\nWestoby, M. (1998). A leaf-height-seed (LHS) plant ecology strategy scheme. Plant and soil, 199, 213-227. https://doi.org/10.1023/A:1004327224729\nWickham H (2023). purrr: Functional Programming Tools. R package version 1.0.1, https://CRAN.R-project.org/package=purrr.\nWickham H (2022). rvest: Easily Harvest (Scrape) Web Pages. R package version 1.0.3, https://CRAN.R-project.org/package=rvest.\n\nData source and citation for plant functional traits:\n\nAxmanová, I. (2022). Plant height. – www.FloraVeg.EU.\nAxmanová, I. (2022). Specific leaf area. – www.FloraVeg.EU.\nAxmanová, I. (2022). Seed mass. – www.FloraVeg.EU.\nFrench Flora database (baseflor), project of Flore et végétation de la France et du Monde: CATMINAT. Available at http://philippe.julve.pagesperso-orange.fr/catminat.htm [accessed June 2020]\nGarcía-Gutiérrez, T., Jiménez-Alfaro, B., Fernández-Pascual, E., & Müller, J. V. (2018). Functional diversity and ecological requirements of alpine vegetation types in a biogeographical transition zone. Phytocoenologia, 77–89. https://doi.org/10.1127/phyto/2017/0224\nGuarino, R., La Rosa, M. & Pignatti, S. (Eds) (2019). Flora d’Italia, volume 4. Bologna: Edagricole.\nHintze, C., Heydel, F., Hoppe, C., Cunze, S., König, A., & Tackenberg, O. (2013). D3: The Dispersal and Diaspore Database – Baseline data and statistics on seed dispersal. Perspectives in Plant Ecology, Evolution and Systematics, 15(3), 180–192. https://doi.org/10.1016/j.ppees.2013.02.001\nLadouceur, E., Bonomi, C., Bruelheide, H., Klimešová, J., Burrascano, S., Poschlod, P., … Jiménez-Alfaro, B. (2019). The functional trait spectrum of European temperate grasslands. Journal of Vegetation Science, 30(5), 777–788. https://doi.org/10.1111/jvs.12784\nKaplan, Z., Danihelka, J., Chrtek, J. Jr., Kirschner, J., Kubát, K., Štěpánek, J. & Štech, M. (Eds) (2019). Klíč ke květeně České republiky [Key to the flora of the Czech Republic]. Ed. 2. Praha: Academia.\nKleyer, M., Bekker, R. M., Knevel, I. C., Bakker, J. P., Thompson, K., Sonnenschein, M., … Peco, B. (2008). The LEDA Traitbase: A database of life-history traits of the Northwest European flora. Journal of Ecology, 96(6), 1266–1274. https://doi.org/10.1111/j.1365-2745.2008.01430.x\nTavşanoğlu, Ç., & Pausas, J. (2018). A functional trait database for Mediterranean Basin plants. Scientific data, 5, 180135. https://doi.org/10.1038/sdata.2018.135"
  },
  {
    "objectID": "posts/lhs_traits.html",
    "href": "posts/lhs_traits.html",
    "title": "Obtain functional traits for European plants",
    "section": "",
    "text": "FloraVeg.EU is a great source to obtain data for the European vegetation, including habitat information and species traits. Some of these information are fully available at the download section. The data on FloraVeg.EU also contains some information on three main functional traits of the ‘leaf-height-seed’ (LHS) scheme proposed in the famous paper by Westoby (1998), namely specific leaf area (SLA), plant height and seed mass.\n\n\n\n\nScreenshot from the FloraVeg.EU website. For each species, some traits of the LHS scheme might be available. Original link: here.\n\n\nThese data are however not (yet!) available in the download section.\nThe best solution to get such trait data is to get in touch with my former group members in Brno (Czech Republic) (see contacts here). Of course databases like TRY and LEDA are also great option, but requires some times to access the data and process them.\nSometimes one just need traits for a few single species for a quick analysis - (or to make comparisons / check outliers of LHS traits with other databases). In such cases one can easily use R to quickly access such information using the rvest R package (Wickham, 2022). This works pretty good if your plant names already follows the nomenclature from Euro+Med!\nN.B.: Please, cite the FloraVeg.EU when using the data obtained this way. See ‘Data source and citation’ below\nHere is the get.LHS.FloraVegEU function:\nget.LHS.FloraVegEU &lt;- function(species) {\n  require(rvest)\n  \n  url &lt;- paste0('https://floraveg.eu/taxon/overview/',species)\n  webpage &lt;- read_html(URLencode(url))\n    \n  #1. Get plant height\n  str_plant.height &lt;- '#panel_2 .featureDetail:nth-child(1) b'\n  plant.height_html &lt;- html_nodes(webpage, str_plant.height)\n  plant.height &lt;- html_text(plant.height_html)\n  plant.height &lt;- gsub('[^0-9.-]', '', plant.height)\n  if(identical(plant.height, character(0))) {plant.height=NA} else {\n    if(plant.height=='' | plant.height=='-') {plant.height=NA} else {\n      plant.height &lt;- as.numeric(plant.height)\n    }\n    }\n    \n  #2. get specific leaf area\n  str_SLA &lt;- '#panel_3 .align-items-center div'\n  SLA_html &lt;- html_nodes(webpage, str_SLA)\n  SLA &lt;- html_text(SLA_html)\n  if(identical(SLA, character(0))){\n    SLA &lt;- NA\n   } else {\n     for (k in 1:length(SLA)) {\n       i2 &lt;- gsub('mm2', '', SLA[[k]])\n       SLA[[k]] &lt;- gsub('[^0-9.-]', '', i2)\n     }\n     SLA &lt;- suppressWarnings(as.numeric(SLA[!is.na(as.numeric(SLA))]))\n     \n     if (identical(SLA, numeric(0))){\n       SLA &lt;- NA\n     }\n     \n  }\n    \n  #3. get seed mass\n  str_SM &lt;- '#panel_5 b'\n  SM_html &lt;- html_nodes(webpage, str_SM)\n  SM &lt;- html_text(SM_html)\n  SM &lt;- gsub('[^0-9.-]', '', SM)\n  SM &lt;- ifelse(identical(SM, character(0)), NA, SM)\n  SM &lt;- as.numeric(SM)\n    \n  res &lt;- data.frame(\n      plant_height = plant.height,\n      sla = SLA,\n      seed_mass = SM)\n\n  return(res)\n}\nTo use the function just type the name of a single species present in the FloraVeg.EU checklist to obtain the results. For example:\n&gt; get.LHS.FloraVegEU('Bellis perennis')\n  plant_height   sla seed_mass\n1         0.09 32.32      0.12\nNote that species nomencalure must correspond the one in FloraVeg.EU. Mispelled species or species for which data are not available will return either an error or NA values. To work with several species and avoid this issue, one can easily apply a modified version of this function using the ‘possibly’ function of the purrr R package (Wickham, 2023).\n#An example of species list (vector):\nsplis = c('Bellis perennis', #Existing species with full LHS information\n          'Pinus mugo', #Existing species with incomplete LHS information\n          'Pseudobetckea caucasica', #Existing species with no information \n          'Taraxacum midolii' #Mispelled / unexisting species\n          )\n\nlibrary(purrr)\nget.LHS.FloraVegEU_possibly &lt;- possibly(get.LHS.FloraVegEU, \n                                        data.frame(plant_height = NA, sla = NA, seed_mass = NA))\nres &lt;- map(splis, get.LHS.FloraVegEU_possibly) #map the function\nnames(res) &lt;- splis #set species names\nres.df &lt;- do.call(rbind, res) # bind dataset\nThe code returns:\n&gt; res.df\n                        plant_height   sla seed_mass\nBellis perennis                 0.09 32.32      0.12\nPinus mugo                      3.12    NA      6.08\nPseudobetckea caucasica           NA    NA        NA\nTaraxacum midolii                 NA    NA        NA\nReferences:\n\nFloraVeg.EU – Database of European Vegetation, Habitats and Flora. www.floraveg.eu\nWestoby, M. (1998). A leaf-height-seed (LHS) plant ecology strategy scheme. Plant and soil, 199, 213-227. https://doi.org/10.1023/A:1004327224729\nWickham H (2023). purrr: Functional Programming Tools. R package version 1.0.1, https://CRAN.R-project.org/package=purrr.\nWickham H (2022). rvest: Easily Harvest (Scrape) Web Pages. R package version 1.0.3, https://CRAN.R-project.org/package=rvest.\n\nData source and citation for plant functional traits:\n\nAxmanová, I. (2022). Plant height. – www.FloraVeg.EU.\nAxmanová, I. (2022). Specific leaf area. – www.FloraVeg.EU.\nAxmanová, I. (2022). Seed mass. – www.FloraVeg.EU.\nFrench Flora database (baseflor), project of Flore et végétation de la France et du Monde: CATMINAT. Available at http://philippe.julve.pagesperso-orange.fr/catminat.htm [accessed June 2020]\nGarcía-Gutiérrez, T., Jiménez-Alfaro, B., Fernández-Pascual, E., & Müller, J. V. (2018). Functional diversity and ecological requirements of alpine vegetation types in a biogeographical transition zone. Phytocoenologia, 77–89. https://doi.org/10.1127/phyto/2017/0224\nGuarino, R., La Rosa, M. & Pignatti, S. (Eds) (2019). Flora d’Italia, volume 4. Bologna: Edagricole.\nHintze, C., Heydel, F., Hoppe, C., Cunze, S., König, A., & Tackenberg, O. (2013). D3: The Dispersal and Diaspore Database – Baseline data and statistics on seed dispersal. Perspectives in Plant Ecology, Evolution and Systematics, 15(3), 180–192. https://doi.org/10.1016/j.ppees.2013.02.001\nLadouceur, E., Bonomi, C., Bruelheide, H., Klimešová, J., Burrascano, S., Poschlod, P., … Jiménez-Alfaro, B. (2019). The functional trait spectrum of European temperate grasslands. Journal of Vegetation Science, 30(5), 777–788. https://doi.org/10.1111/jvs.12784\nKaplan, Z., Danihelka, J., Chrtek, J. Jr., Kirschner, J., Kubát, K., Štěpánek, J. & Štech, M. (Eds) (2019). Klíč ke květeně České republiky [Key to the flora of the Czech Republic]. Ed. 2. Praha: Academia.\nKleyer, M., Bekker, R. M., Knevel, I. C., Bakker, J. P., Thompson, K., Sonnenschein, M., … Peco, B. (2008). The LEDA Traitbase: A database of life-history traits of the Northwest European flora. Journal of Ecology, 96(6), 1266–1274. https://doi.org/10.1111/j.1365-2745.2008.01430.x\nTavşanoğlu, Ç., & Pausas, J. (2018). A functional trait database for Mediterranean Basin plants. Scientific data, 5, 180135. https://doi.org/10.1038/sdata.2018.135"
  },
  {
    "objectID": "posts/pairwise_cor_viz.html",
    "href": "posts/pairwise_cor_viz.html",
    "title": "Simple pairwise visualizations for incomplete datasets",
    "section": "",
    "text": "This is my first post. It is going to be an easy one.\nIt often happens that a species × trait matrix (or any data set really) is incomplete because of missing trait information (some species may have some traits, while others don’t). In my experience, this makes difficult to check pairwise correlations using common visualization tools in R. Here, I report an R code to plot pairwise correlation estimates retaining complete observations (with cor(..., use=\"pairwise.complete.obs\")) for each pair in the lower-right panel and reporting the sample size in the upper-left panel. This way, one can always know how many species report trait data information for each pair and check their correlation value.\n\n#Plot correlation matrix with gaps\n\n#1. Accessory functions ####\ngetsamplesize &lt;- function(vec_a, vec_b) {\n  nrow(drop_na(data.frame(vec_a,vec_b)))\n}\nfirstup &lt;- function(x) {\n  substr(x, 1, 1) &lt;- toupper(substr(x, 1, 1))\n  x\n}\nget_lower_tri&lt;-function(cormat){\n  cormat[upper.tri(cormat)] &lt;- NA\n  return(cormat)\n}\nget_upper_tri &lt;- function(cormat){\n  cormat[lower.tri(cormat)]&lt;- NA\n  return(cormat)\n}\n\n#2. load the function\n#N.B. this function requires tidyverse, reshape2, and corrr packages\n\nplot.inc.cor &lt;- function(mat, round.label.digit=2, cor.method='pearson', size.label=4){\n  \n  corm &lt;- cor(mat, method = cor.method, use=\"pairwise.complete.obs\")\n  \n  pcorm &lt;- cor(mat, method = cor.method, use=\"pairwise.complete.obs\") %&gt;%\n    get_lower_tri %&gt;%\n    reshape2::melt()\n  pcorm$value = ifelse(pcorm$Var1 == pcorm$Var2, NA, pcorm$value)\n  psams &lt;- corrr::colpair_map(mat, getsamplesize) %&gt;%\n    as.data.frame %&gt;%\n    tibble::column_to_rownames('term') %&gt;%\n    as.matrix %&gt;%\n    get_upper_tri %&gt;%\n    reshape2::melt() %&gt;%\n    setNames(names(pcorm)) \n  \n  pcorm$value = round(pcorm$value, round.label.digit)\n  # Format the numeric values with two decimal places\n  pcorm$formatted_value &lt;- sprintf(paste0('%.',round.label.digit,'f'), pcorm$value)\n  pcorm$formatted_value &lt;- ifelse(pcorm$formatted_value=='NA',NA,pcorm$formatted_value)\n  \n  p &lt;- ggplot() + \n    geom_tile(data = pcorm, aes(x=Var1, y=Var2, fill=value), color='grey80')+\n    geom_text(data = psams, aes(x=Var1, y=Var2, label = value, alpha=log(value)), color = \"black\", size = size.label) +\n    geom_text(data = pcorm, aes(x=Var1, y=Var2, label = formatted_value), color = \"black\", size = size.label) +\n    scale_fill_gradient2(low = \"#4A6FE3\", mid = \"white\", high = \"#D33F6A\", \n                         midpoint = 0, limit = c(-1,1), space = \"Lab\", \n                         na.value = 'white',\n                         name=paste0(firstup(cor.method),'\\ncorrelation')) +\n    theme_classic() +\n    guides(alpha='none')+\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, color='black'),\n          axis.text.y = element_text(color='black'),\n          axis.title = element_blank(),\n          axis.line = element_blank(),\n          panel.background = element_rect(fill = \"white\",\n                                          colour = \"white\")) +\n    coord_fixed() +\n    geom_abline(slope = 1, intercept = 0, color='grey80') \n  return(p)\n}\nSimulate some data and visualize the output with the plot.inc.cor function:\nset.seed(9)\n\nlibrary(tidyverse); library(reshape2); library(corrr)\n\n# Number of rows and columns in the dataframe\nnum_species &lt;- 100\nnum_traits &lt;- 7\n\n# Generate random data with NAs\ndmatrix &lt;- matrix(runif(num_species * num_traits), nrow = num_species)\n\n# Randomly replace 25% of values with NA\ndmatrix[sample(length(dmatrix), length(dmatrix)*0.25)] &lt;- NA\n\n# Convert the matrix to a dataframe\ndmatrix &lt;- as.data.frame(dmatrix)\nnames(dmatrix) = paste0('Trait',1:ncol(dmatrix))\n\nplot.inc.cor(dmatrix, cor.method='pearson', round.label.digit=2, size.label=3)\n\n\n\nExample of output obtained, using default options. Upper left panel displays the number of observations without NAs (complete cases) for each pair; bottom right panel shows their correlation coefficient (default is ‘pearson’)."
  },
  {
    "objectID": "posts/calc_rli.html",
    "href": "posts/calc_rli.html",
    "title": "Measuring species range elongation",
    "section": "",
    "text": "Species range shape refers to how a species’ distribution differs from a perfectly symmetrical or isotropic pattern expected under neutral range dynamics. Some researchers have indeed proposed estimating shape elongation as a significant biogeographical species attribute (Rapoport, 1982; Brown et al., 1996; Pigot et al., 2010; Baselga et al., 2012; Castro-Insua et al., 2018).\nHere I share an R code (= the get_RLI function) to calculate a metric similar to what described as the Range Linearity Index (RLI) by Pigot et al. (2010). The RLI is a dimensionless measure calculated as RLI = l2 / a, where l represents the maximum linear dimension, and a represents the area of the polygon. To compute the l metric, we will determine the longest length among the shortest paths connecting all possible combinations of the westernmost, easternmost, northernmost, and southernmost geographical points at the extremes of each polygon. As a result, the RLI offers an intuitive way to quantify shape elongation, analogous to the long axis to width ratio (Graves 1988; Pigot et al. 2010). For example, an RLI value of 2 indicates a shape that is twice as long as it is wide.\nI used this function to study the relationships between range attributes and functional traits of European trees. For additional details, please refer to the tutorial below and to my publication available online: Midolo (2024) in Global Ecology and Biogeography. You can also download the get_RLI function here.\n\n\n\nWorkflow to calculate range shape (= range elongation calculated as the Range Linearity Index, RLI) in the get_RLI function. The figure illustrates a schematic example for the native range of the wych elm (Ulmus glabra) (data source: Caudullo et al. 2017). Panel a) display the whole range of the species. Panel b) shows the largest range portions (= fragments) selected for RLI calculation (the biggest range fragments are used by default based on the rationale these are more important in defyining the whole range shape). RLI for species w is calculated as the average of RLI values of each range fragment (RLIi). RLI is the dimensioness ratio between squared length (l2) and area of the polygon, where l is the longest path across the shortest distance between the geographical points located at the extremes of each polygon (line in red; panel c). Maps are displayed with UTM EPSG:32633 projection.\n\n\nHere is the code for the get_RLI function:\nget_RLI &lt;- function(range, # a multi polygons sf object of the species range\n                    directional.constraint='none', # constraint the shortest path? default is none, use 'lon' or 'lat' to constrain the paths along longitude or latitude\n                    fragment.inclusivity = 0.1, # the lowest this value, the highest is the proportion of fragments considered for range calculation. Lowest fragments \n                    columns.and.rows=100, # number of col and rows of the raster for each range fragment, increasing this number makes a raster with finer resolution, increasing considerably the amount of time!\n                    direction = 8, # the 'directions' argument of the gdistance::transition() function. Values of 4, 8 and 16 are reccomended\n                    graphical = T, # if T, plot the range with line objects (paths) used for RLI estimation\n                    col.bl='red', # if graphical == T, the color of the final paths used for RLI estimation in the graph\n                    very.graphical = F) # plot each fragment under examination and its candidate paths\n  {\n  st=Sys.time()\n  \n  UTM32 = '+proj=utm +zone=32 +datum=WGS84 +units=m +no_defs'\n  orirange &lt;- st_sf(range) # trasform to sf object\n  st_geometry(orirange) &lt;- 'geometry'\n  orirange &lt;- st_transform(orirange, UTM32) #reproject to UTM zone 32\n  rprp &lt;- orirange %&gt;% st_cast('POLYGON') # cast to POLYGON (= separating fragments)\n  rprp$area &lt;- as.numeric(st_area(rprp$geometry)) # calculate area for each fragment in m^2\n  rprp = rprp %&gt;% arrange(desc(area))\n  rprp$adif &lt;- rprp$area/max(rprp$area) # proportional area difference with the nmain range\n  #exclude too small fragments:\n  rprpo = rprp\n  rprp = rprp[rprp$adif&gt;=fragment.inclusivity,]\n  rprp$id = 1:nrow(rprp)\n  \n  print(paste0('Assessing ',nrow(rprp),' range fragments out of ', nrow(rprpo)))\n  \n  sentieri &lt;- list() #list where to store fragments' RLI stats\n  for (frag in 1:nrow(rprp)) {\n    \n    st.i &lt;- Sys.time()\n    \n    polyi &lt;- rprp[frag,]\n    #apply Behrman transofmration, lon_0 set depending upon longitudinal extension (correcting for distortion)\n    polyi = st_transform(polyi, crs = '+proj=cea +lon_0=0 +lat_ts=30 +x_0=0 +y_0=0 +datum=WGS84 +ellps=WGS84 +units=m +no_defs')\n    if(round(abs(min(st_coordinates(polyi)[,1]))) == round(abs(max(st_coordinates(polyi)[,1])))){\n      polyi = st_transform(rprp[frag,], crs = '+proj=cea +lon_0=10 +lat_ts=30 +x_0=0 +y_0=0 +datum=WGS84 +ellps=WGS84 +units=m +no_defs')\n    }\n    \n    crs.polyi &lt;- crs(as_Spatial(polyi))\n    \n    poly.grid &lt;- st_make_grid(polyi, n=rep(columns.and.rows,2)) %&gt;%\n      st_sf() %&gt;%\n      mutate(row.id = row_number())\n    \n    defaultW &lt;- getOption(\"warn\")\n    \n    #1. define the area where the line can pass through (= 'playground')\n    options(warn = -1)\n    playground &lt;- poly.grid %&gt;%\n      left_join(\n        as.data.frame(st_intersects(poly.grid,polyi))%&gt;%rename(value = col.id),'row.id'\n      ) %&gt;% dplyr::select(-row.id) %&gt;%\n      st_cast('POINT') %&gt;%\n      as_Spatial() %&gt;% \n      as.data.frame() %&gt;% \n      setNames(c('z','x','y')) %&gt;% \n      dplyr::select(x,y,z) %&gt;%\n      rasterFromXYZ(crs = crs.polyi)\n    options(warn = defaultW)\n    \n    #plot:\n    if(very.graphical) {plot(playground, col='grey',main=paste0('fragment n. ',frag),legend=F)}\n    \n    \n    #2. define the start/arrival point cells (= 'rallypoints')\n    coord &lt;- st_coordinates(polyi) %&gt;% as.data.frame()\n    \n    options(warn = -1)\n    rallypoints &lt;- list(\n      southernmost = coord[which.min(coord[, \"Y\"]), ],\n      northernmost = coord[which.max(coord[, \"Y\"]), ],\n      easternmost = coord[which.max(coord[, \"X\"]), ],\n      westernmost = coord[which.min(coord[, \"X\"]), ]\n    ) %&gt;% \n      bind_rows(.id='flag') %&gt;%\n      st_as_sf(coords=c(\"X\",\"Y\"), crs = st_crs(polyi)) %&gt;%\n      dplyr::select(flag,geometry)\n    \n    raster.cooord &lt;- poly.grid %&gt;%\n      left_join(\n        as.data.frame(st_intersects(poly.grid,rallypoints))%&gt;%rename(value = col.id),'row.id'\n      ) %&gt;% \n      filter(!is.na(value)) %&gt;%\n      dplyr::select(-row.id) %&gt;%\n      st_centroid() %&gt;%\n      st_coordinates %&gt;%\n      as.data.frame()\n    \n    rallyrasters &lt;- list(\n      southernmost = raster.cooord[which.min(raster.cooord[, \"Y\"]), ],\n      northernmost = raster.cooord[which.max(raster.cooord[, \"Y\"]), ],\n      easternmost = raster.cooord[which.max(raster.cooord[, \"X\"]), ],\n      westernmost = raster.cooord[which.min(raster.cooord[, \"X\"]), ]\n    ) %&gt;% \n      bind_rows(.id='flag')\n    \n    options(warn = defaultW)\n    \n    if(directional.constraint == 'lon') {\n      rallyrasters &lt;- rallyrasters %&gt;% filter(flag == 'easternmost' | flag == 'westernmost')\n    }\n    \n    if(directional.constraint == 'lat') {\n      rallyrasters &lt;- rallyrasters %&gt;% filter(flag == 'southernmost' | flag == 'northernmost')\n    }\n    \n    rallyrasters_spatial &lt;- rallyrasters %&gt;% st_as_sf(coords = c('X','Y'), crs=crs.polyi)\n    \n    #3. force misplaced points towards raster, if needed\n    check.allocation &lt;- raster::extract(playground,rallyrasters_spatial)\n    if (any(is.na(check.allocation))){\n      badpoints &lt;- rallyrasters[is.na(check.allocation),] %&gt;% st_as_sf(coords=c('X','Y'))\n      for (k in 1:nrow(badpoints)) {\n        vvo &lt;- rasterToPoints(playground) %&gt;% as.data.frame() %&gt;% filter(!is.na(z))\n        vv &lt;- st_as_sf(vvo,coords=c('x','y'))\n        vv$dist &lt;- st_distance(vv$geometry, badpoints[k,]$geometry)\n        new.alloc &lt;- vvo[which(vv$dist == min(vv$dist)),] %&gt;% sample_n(1)\n        rallyrasters[is.na(check.allocation),][,2:3][k,]$X = new.alloc$x\n        rallyrasters[is.na(check.allocation),][,2:3][k,]$Y = new.alloc$y\n      }}\n    \n    rallyrasters_spatial &lt;- rallyrasters %&gt;% st_as_sf(coords = c('X','Y'), crs=crs.polyi)\n    \n    if(very.graphical) {\n      rallyrasters_spatial$flagcol = c(rep('grey30',4))[1:nrow(rallyrasters)]\n      plot(rallyrasters_spatial, col=rallyrasters_spatial$flagcol,add=T,legend=F, pch=16)\n    }\n    \n    thepoints2test &lt;- rallyrasters[,-1]\n    thepoints2test$id &lt;- 1:nrow(thepoints2test)\n    \n    egrid_unique.combs &lt;- as.data.frame(t(combn(thepoints2test$id,2))) %&gt;% \n      bind_rows(data.frame(V1=thepoints2test$id,V2=thepoints2test$id)) %&gt;% \n      setNames(c('n1','n2')) #a non-redundant version of expand_grid\n    \n    egrid &lt;- cbind(\n      expand_grid(n1=thepoints2test$id, n2=thepoints2test$id),\n      expand_grid(d1=cbind(thepoints2test$X,thepoints2test$Y), d2=cbind(thepoints2test$X,thepoints2test$Y))\n    ) %&gt;% \n      semi_join(egrid_unique.combs, by=c('n1','n2'))%&gt;% #a non-redundant tibble of pairwise combinations\n      filter(n1!=n2)\n    egrid &lt;- egrid[,-c(1,2)]\n    \n    tr1 &lt;- gdistance::transition(playground, transitionFunction=mean, directions=direction)\n    tr1 &lt;- gdistance::geoCorrection(tr1,'c')\n    \n    #start detecting the possible paths...\n    if(very.graphical) {vcol &lt;- viridis::viridis(nrow(egrid),direction = 1)}\n    linee &lt;- list()\n    lunghezze &lt;- vector()\n    for (l in 1:nrow(egrid)) {\n      linee[[l]] &lt;- gdistance::shortestPath(tr1, \n                                    as.numeric(egrid[l,1]),\n                                    as.numeric(egrid[l,2]),\n                                    output=\"SpatialLines\") %&gt;%\n        st_as_sf() %&gt;%\n        st_set_crs(tr1@srs) %&gt;%\n        st_transform(st_crs(orirange))\n      \n      if(very.graphical){plot(linee[[l]] %&gt;% st_transform(crs(playground)), add=T, col=vcol[l],lwd=2, lty=1)}\n      lunghezze[l] &lt;- as.numeric(st_length(linee[[l]]))\n    }\n    \n    I.stat &lt;- max(lunghezze)\n    a &lt;- polyi$area\n    \n    which.best.line &lt;- c(which(lunghezze == I.stat))\n    bl.id &lt;- ifelse(length(which.best.line) == 1, which.best.line, sample(which.best.line,1))\n    bl &lt;- linee[[bl.id]]\n\n    sentieri[[frag]] &lt;- list(\n      best.path = bl,\n      df = data.frame(fragment=frag, I=I.stat, A=a, RLI = as.numeric(I.stat)^2/a)\n    )\n    \n    cati = str_pad(frag,nchar(nrow(rprp)),side='left',pad='0')\n    et.i = Sys.time() - st.i\n    message('Fragment ',cati,' time: ',paste(round(et.i,2)),' ',attr(et.i,'units'))\n  }\n  \n  \n  out = list(\n    RLI.vals = bind_rows(purrr::map(sentieri, function(x){x$df})),\n    RLI.lins = bind_rows(purrr::map(sentieri, function(x){st_sf(x$best.path)}))\n  )\n  \n  if(graphical){\n    plot(as_Spatial(orirange), col='black', border=NA)\n    plot(as_Spatial(rprp),col='darkolivegreen3',add=T,border=NA)\n    plot(out$RLI.lins, col=col.bl, add=T, lwd=3)\n  }\n  \n  et=Sys.time()-st\n  message(paste0('... DONE! Total elapsed time: ',paste(round(et,2)),' ',attr(et,'units')))\n  return(out)\n}\nHere is a simple tutorial. In this example, we calculate RLI for Taurus fir (Abies cilicica), a tree species growing in Lebanon and Turkey. The original native range was downloaded here (source: Caudullo et al. 2017).\n#1. prepare the data\n\n#the function depends upon the following R packages:\n\nlibrary(tidyverse); library(sf); library(raster); library(gdistance)\n\n#define coordinates of the simplifed range of Taurus fir\n\ncoords &lt;- \"MULTIPOLYGON (((30.70949 37.44737, 30.47034 37.32006, 30.52049 37.20553, 30.71815 37.2789, 30.70949 37.44737)), ((31.11012 37.42078, 30.97528 37.4679, 30.88733 37.36318, 30.93263 37.24811, 31.11012 37.42078)), ((36.46468 37.03979, 36.31841 36.89317, 36.33939 36.7773, 36.49918 36.8471, 36.46468 37.03979)), ((36.6707 37.29474, 36.66847 37.51403, 36.59149 37.58607, 36.59808 37.87782, 36.73713 37.93399, 36.84522 37.90433, 36.96676 37.9688, 36.96026 38.04769, 36.70301 38.12471, 36.67512 38.18166, 36.54407 38.27753, 36.43666 38.13201, 36.15473 38.10206, 36.21972 38.26696, 36.29701 38.28576, 36.39462 38.32924, 36.09729 38.36283, 35.89325 38.15608, 35.73671 38.09842, 35.69503 37.97337, 35.24333 37.68169, 35.04145 37.78691, 34.84408 37.54285, 34.47599 37.51281, 34.39836 37.40821, 34.6797 37.42135, 34.68839 37.31277, 34.55881 37.28519, 34.27545 37.15911, 34.18091 36.91732, 33.99108 36.94332, 33.80763 36.56233, 34.02319 36.61594, 34.19481 36.74509, 34.34339 36.97006, 34.59568 37.03146, 34.63063 37.1486, 34.94324 37.24132, 34.98489 37.32413, 35.56452 37.59327, 35.79142 37.8377, 35.8945 38.05866, 35.97055 37.94501, 35.95044 37.6577, 36.13366 37.56702, 36.30933 37.58298, 36.43974 37.49443, 36.46066 37.35781, 36.6707 37.29474)), ((36.23528 34.52347, 35.98332 34.34524, 35.96573 34.2879, 36.28164 34.46973, 36.23528 34.52347)), ((31.27839 37.37006, 31.34101 37.04838, 31.52389 36.88489, 31.95332 36.8085, 32.09129 36.57597, 32.23787 36.55928, 32.48722 36.16406, 33.13701 36.23291, 33.17804 36.38689, 33.09851 36.40655, 33.05761 36.52104, 32.96027 36.36613, 32.73956 36.37612, 32.63873 36.26141, 32.5014 36.32853, 32.48627 36.75422, 32.34106 36.76603, 32.26759 36.84551, 32.28035 36.75343, 32.11068 36.73524, 32.08518 36.86551, 31.86951 36.9232, 31.95336 37.16447, 31.70671 37.38032, 31.4169 37.29067, 31.27839 37.37006)), ((32.93654 36.86382, 32.99047 36.65178, 33.08621 36.62425, 33.04779 36.8336, 32.93654 36.86382)))\"\n\n#coordinates to multipolygon sf object:\n\nrange &lt;- st_as_sfc(coords, crs='+proj=longlat +datum=WGS84 +no_defs')\n\n#quickly visualise the geometry in a map (optional, requires mapview):\n\nmapview::mapview(range)\n\n\n\nSimplified polygon shape for Taurus fir (Abies cilicica) using mapview\n\n\nNow, let’s run the get_RLI function, with default options:\n#run the function with default options:\nres &lt;- get_RLI(range)\n[1] \"Assessing 2 range fragments out of 7\" \nFragment 1 time: 2.82 secs \nFragment 2 time: 3.04 secs \n... DONE! Total elapsed time: 5.94 secs \n\n\n\nGraphical output obtained from the function at the end of RLI calculation (set graphical=FALSE to supress the plotting). By default the function displays the different fragments composing species ranges and the longest paths (in red). These are only calculated and drawn for the range fragments considered in the analysis (in green; unutilized range fragment are displayed in black).\n\n\nLet’s inspect the results:\nres$RLI.vals # values of RLI for each fragment, units are in m\n  fragment        I           A      RLI\n1        1 248601.8  5779445898 10.69356\n2        2 374410.0 12863135567 10.89803\n\nweighted.mean(res$RLI.vals$RLI, w = res$RLI.vals$A) # obtain RLI, weighted by the size of each fragment\n10.83464\n\nres$RLI.lins # LINESTRING geometries (the drawn lines)\nWe calculated the species-level RLI, using the average of the RLI of each fragment weighted by its area A. We conclude that range elongation of Abies cilicica is quite pronounced (RLI = 10.8), meaning it is almost about eleven times long as it is wide.\nWe can allow the function to return some plot displaying all possible shorthests path considered for each range fragment included in the analysis by setting the parameter very.graphical=TRUE.\n# show the intermediate steps of calculation for each path\nget_RLI(range, very.graphical = T, graphical = F) \n\n\n\nAll possible paths considered in each of the fragments assessed. Across each of the four path, the longest one is selected to calculate l by default. N.B. the geographic coordinates on the xy follow the Behrman transformation for estimation of geographic extremes.\n\n\nIn some systems, one may want to focus exclusively upon the elongation along either longitude or latitude. For example, given the south-to-north distribution of Andean montane forests, one might be interested in knowing the elongation of a species along latitude (e.g. see Graves 1988). On the other hand, range elongation along longitiude might be a good indicator for e.g. plant species constrained to coastal lines in the Mediterranean. In this context, we can simply force the function to consider only northermost-to-southernmost points with directional.constraint = 'lat' or westernmost-to-easternmost points with directional.constraint = 'lon' (default is directional.constraint = 'none')\n#constraint shortest path only latitude or longitude paths\nget_RLI(range, directional.constraint = 'lat', col.bl = 'red')\nget_RLI(range, directional.constraint = 'lon', col.bl = 'blue')\n\n\n\nThe visual output obtained when directional.constraint parameter is modified accordingly (edited figures)\n\n\nFinally, one may also consider more fragments for RLI calculation, as in principle there is no reason to exclude smallest fragments. However, I) range polygons could be much more complex and bigger than what we are using here, resulting into non-negligible computation times for this function, and II) the RLI calculation weighted by area makes nearly useless to consider all possible tiny fragments composing a species range. Anyway, we can modify the fragment.inclusivity parameter to do so (default here is setted to 0.1). This is a threshold value. It allows the inclusion of fragments by calculating the ratio between the area of each fragment to the area of the fragment with the largest area. Only fragments with values greater or equal to fragment.inclusivity are included for RLI calculation. Thus, the lowest this value, the highest is the proportion of fragments considered for range calculation. Set fragment.inclusivity=0 if you want all fragments to be considered for RLI estimation.\n#decrease inclusivity treshold for range fragments (i.e., consider an increasing number of smaller fragments for RLI estimation) \nres2 &lt;- get_RLI(range, fragment.inclusivity = 0.02) # default is 0.1\n\n\n\n\n\n&gt; res2$RLI.vals # we now included more fragments\n  fragment         I           A       RLI\n1        1  34405.63   304506996  3.887422\n2        2  34215.45   364252009  3.213975\n3        3 248601.78  5779445898 10.693559\n4        4 374409.97 12863135567 10.898029\n\n&gt; weighted.mean(res2$RLI.vals$RLI, w = res2$RLI.vals$A) #but they matter less in overall RLI calculation\n[1] 10.58135\nYou can see we have now two smaller fragments considered for RLI calculation. Yet, these new smaller fragments weight less in the final average, and thus they do not affect the final RLI calculation that much. Again, this follow the assumption that smaller ranges matter less for overall range shape estimation.\nReferences\n\nBaselga, A., Lobo, J. M., Svenning, J. C., & Araújo, M. B. (2012). Global patterns in the shape of species geographical ranges reveal range determinants. Journal of Biogeography, 39(4), 760–771.\nBrown, J. H., Stevens, G. C., & Kaufman, D. M. (1996). The Geographic Range: Size, Shape, Boundaries, and Internal Structure. Annual Review of Ecology and Systematics, 27(1), 597–623.\nCastro‐Insua, A., Gómez‐Rodríguez, C., Svenning, J. C., & Baselga, A. (2018). A new macroecological pattern: The latitudinal gradient in species range shape. Global Ecology and Biogeography, 27(3), 357-367.\nCaudullo, G., Welk, E., & San-Miguel-Ayanz, J. (2017). Chorological maps for the main European woody species. Data in Brief, 12, 662–666.\nGraves, G. R. (1988). Linearity of Geographic Range and Its Possible Effect on the Population Structure of Andean Birds. The Auk, 105(1), 47–52. \nMidolo, G. (2024). Plant functional traits couple with range size and shape in European trees. Global Ecology and Biogeography, 33(6), e13838.\nPigot, A. L., Owens, I. P. F., & Orme, C. D. L. (2010). The environmental limits to geographic range expansion in birds. Ecology Letters, 13(6), 705–715.\nRapoport, E. H. (1982). Aerography: Geographical Strategies of Species. Pergamon Press, Oxford UK."
  },
  {
    "objectID": "posts/ts_sentiment.html",
    "href": "posts/ts_sentiment.html",
    "title": "Taylored Sentiments",
    "section": "",
    "text": "Here I use sentiment analysis\n\n\n\n\nAI-generated using OpenAI tools. Free for non-commercial use with attribution."
  },
  {
    "objectID": "posts/intrpl_houseprice.html",
    "href": "posts/intrpl_houseprice.html",
    "title": "Reconstructing historical house price dynamics across the United States without time series data",
    "section": "",
    "text": "Time series data can often be gappy in space and time. Here, I illustrate a spatiotemporal machine learning (ML) interpolation exercise showing that it is possible to predict temporal changes at any point in time for a variable of interest from sparse geographic data (i.e., data without temporal replication at a site). This approach works when the variable of interest is spatially and temporally autocorrelated (Tobler, 1970), so that the space-time cube (Mahecha et al., 2020) can be filled using ML models trained on data with just one observation at each site that account for the complex interaction between space, time, and area (Keil & Chase, 2022).\nAs an ecologist by training, we recently utilized this approach to study species richness dynamics (see also the work of Keil & Chase, 2022. Here, I illustrate how this approach can be applied very well also in other contexts, such as the changes in prices of houses arranged across postal codes of the United States. Specifically, I utilized temporal time series of house prices across 26,318 zip addresses across the U.S. available from Zillow Housing Data. I used smoothed, seasonally adjusted, Zillow Home Value Index (ZHVI) prices for all homes tipes (SFR and Condo/Co-op). The time serie cover 25 years, ranging from 31 December 2000 to 31 March 2025."
  },
  {
    "objectID": "posts/intrpl_houseprice.html#background",
    "href": "posts/intrpl_houseprice.html#background",
    "title": "Reconstructing historical house price dynamics across the United States without time series data",
    "section": "",
    "text": "Time series data can often be gappy in space and time. Here, I illustrate a spatiotemporal machine learning (ML) interpolation exercise showing that it is possible to predict temporal changes at any point in time for a variable of interest from sparse geographic data (i.e., data without temporal replication at a site). This approach works when the variable of interest is spatially and temporally autocorrelated (Tobler, 1970), so that the space-time cube (Mahecha et al., 2020) can be filled using ML models trained on data with just one observation at each site that account for the complex interaction between space, time, and area (Keil & Chase, 2022).\nAs an ecologist by training, we recently utilized this approach to study species richness dynamics (see also the work of Keil & Chase, 2022. Here, I illustrate how this approach can be applied very well also in other contexts, such as the changes in prices of houses arranged across postal codes of the United States. Specifically, I utilized temporal time series of house prices across 26,318 zip addresses across the U.S. available from Zillow Housing Data. I used smoothed, seasonally adjusted, Zillow Home Value Index (ZHVI) prices for all homes tipes (SFR and Condo/Co-op). The time serie cover 25 years, ranging from 31 December 2000 to 31 March 2025."
  },
  {
    "objectID": "posts/intrpl_houseprice.html#references",
    "href": "posts/intrpl_houseprice.html#references",
    "title": "Reconstructing historical house price dynamics across the United States without time series data",
    "section": "References",
    "text": "References\n\nBreiman L., Random forests. Machine Learning 45, 5–32 (2001).\nKeil, P. & Chase, J. Interpolation of temporal biodiversity change, loss, and gain across scales: a machine learning approach. EcoEvoRxiv (2022)\nMahecha, M. D. et al. Earth system data cubes unravel global multivariate dynamics. Earth System Dynamics 11, 201–234 (2020)\nTobler, W. R. A Computer Movie Simulating Urban Growth in the Detroit Region. Economic Geography 46, 234 (1970)\nWright, M. N. & Ziegler, A. ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R. Journal of Statistical Software 77 (2017)."
  },
  {
    "objectID": "posts/old/ts_sentiment.html",
    "href": "posts/old/ts_sentiment.html",
    "title": "Taylored Sentiments",
    "section": "",
    "text": "Here I use sentiment analysis\n\n\n\n\nAI-generated using OpenAI tools. Free for non-commercial use with attribution."
  },
  {
    "objectID": "posts/intrpl_houseprice.html#data-preparation",
    "href": "posts/intrpl_houseprice.html#data-preparation",
    "title": "Reconstructing historical house price dynamics across the United States without time series data",
    "section": "2. Data preparation",
    "text": "2. Data preparation\nAs the Zillow dataset does not contain the longitude and latitude of ZIP code addresses, I utilized an external source containing geographic information for each ZIP code, available on kaggle.com. This dataset offers geographic coordinates in WGS84. I transformed these coordinates (x, y) into meters (using EPSG:5070 - NAD83/Conus Albers projection) so that we can use this information for better statistical interpolation. Concerning time, I standardized it so that it is expressed in days elapsed from the 1st of January 2000.\n\n# load R packages\nlibrary(tidyverse)\nlibrary(sf)\n\n# Load ZIP code 7geographic data (downloaded from: https://www.kaggle.com/datasets/jedwible/uszipcodes-20231227)\nzips &lt;- \"./data/USZipsWithLatLon_20231227.csv\" %&gt;%\n  read_csv(show_col_types = F) %&gt;%\n  # select variables of interest\n  select(`postal code`, latitude, longitude) %&gt;%\n  # add coordinates in meters (NAD83 / Conus Albers, EPSG:5070)\n  st_as_sf(coords = c('longitude','latitude'), remove = F, crs = 'WGS84') %&gt;%\n  st_transform(crs = 5070) %&gt;%\n  # transform back to dataframe object\n  as_Spatial() %&gt;%\n  as.data.frame() %&gt;%\n  rename(x=coords.x1, y=coords.x2)\n  \n# Load Zillow data (downloaded from: https://www.zillow.com/research/data)\nzillow_dat &lt;- './data/Zip_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv' %&gt;%\n  read_csv(show_col_types = F)\n\n# Merge Zillow data to geolocation data & tidy the data\nzillow_dat &lt;- zillow_dat %&gt;%\n  # merge coordinates to ZIP data\n  left_join(zips, by = c('RegionName' = 'postal.code')) %&gt;%\n  select(RegionName, longitude, latitude, x, y, everything() )%&gt;%\n  # gather price and time\n  gather('rawdate','price', 14:ncol(.), na.rm = T) %&gt;%\n  arrange(RegionName) %&gt;%\n  # extract date and calculate time (days) elapsed since baseline date (1st Jan 2000)\n  mutate(rawdate = as.Date(rawdate)) %&gt;%\n  mutate(time = as.numeric(rawdate - as.Date('2000-01-01'))) %&gt;%\n  group_by(RegionName) %&gt;%\n  mutate(time_span_years = max(time)-min(time), .after= RegionName) %&gt;%\n  ungroup()\n\nThe data comprehend time series for each ZIP code in the U.S. For example, here is how the temporal trend of prices looks in Beverly Hills (Los Angeles) - a region known for very high property values:\n\n\n\n\n\n\n\n\n\nThe time series covers each of these locations (however, note that not all ZIP codes have data across the entire 25 years period):"
  },
  {
    "objectID": "posts/intrpl_houseprice.html#model-training",
    "href": "posts/intrpl_houseprice.html#model-training",
    "title": "Reconstructing historical house price dynamics across the United States without time series data",
    "section": "3. Model training",
    "text": "3. Model training\nI will employ Random Forests (Breiman, 2001) using the ‘ranger’ engine (Wright & Ziegler, 2017) to model the dependence of price to geographic coordiantes (x, y) and time. \\[\nprice \\sim x + y + time\n\\] Given repeated observations at each U.S. ZIP code, I tested the robustness of our temporal price interpolation by training our model on sites without replication in time. To this end, I generated a static dataset by randomly sampling one price observation at a random time for each U.S. ZIP code.\n\n# Generate random static dataset\nset.seed(123)\nd_static &lt;- zillow_dat %&gt;%\n  group_by(RegionName) %&gt;%\n  sample_n(1) %&gt;%\n  ungroup()\n\nThe space-time cube representation of our data is visualized below (showing 1000 observations only for clarity), with colored points being our response variable to be interpolated in time.\n\n\n\n\n\n\n\n\n\nI tuned and trained our model using tidymodels:\n\nlibrary(tidymodels)\nlibrary(future)\n\n# Prepare data for modeling and split train and test dataset\nset.seed(234)\ndat_split &lt;- \n  d_static %&gt;%\n  ## select variables for modeling\n  select(RegionName, price, x, y, time) %&gt;%\n  ## split the data\n  initial_split(prop = 4/5, strata = price)\n\n# Subset training set\ndat_train &lt;- training(dat_split) \n\n# Get CV folds\nset.seed(345)\ncv_random_folds &lt;- vfold_cv(dat_train, v = 10, repeats = 1, strata = price)\n\n# Define recipe\nrec &lt;- recipe(price ~ x + y + time, data = dat_train) %&gt;%\n  step_normalize(all_numeric_predictors())\n\n# Define model \nspec &lt;- rand_forest(\n  trees = 500, \n  min_n = tune(),\n  mtry = tune()\n) %&gt;%\n  set_mode('regression') %&gt;%\n  set_engine('ranger', importance = 'impurity', seed = 1975)\n\n# Define workflow\nwflow &lt;- workflow() %&gt;%\n  add_model(spec) %&gt;%\n  add_recipe(rec)\nwflow\n\n# Define tune grid\ngrd_tune &lt;- expand.grid(\n  min_n = c(2,5,10,15,20),\n  mtry = c(2:3)) %&gt;%\n  as_tibble()\nglimpse(grd_tune)\n\n# Perform tuning\nset.seed(456)\nplan(multisession, workers = 4)\nst = Sys.time()\ntune_res &lt;- tune_grid(\n  object = wflow,\n  resamples = cv_random_folds,\n  grid = grd_tune,\n  metrics = metric_set(rmse, rsq)\n)\nprint(Sys.time()-st)\nplan(sequential)\n\n# Export tuning results\ntune_res %&gt;%\n  write_rds('./data/models/RF.tune_res.rds')\n\n# Select the best performing sets of parameters\ntune_best &lt;- select_best(tune_res, metric = 'rmse')\ntune_best\n\n# Finalize workflow, fit on training data and test on testing data\nlfit &lt;- wflow %&gt;%\n  finalize_workflow(tune_best) %&gt;%\n  last_fit(dat_split)\n\n# Export last fit\nlfit %&gt;%\n  write_rds('./data/models/RF.last_fit.rds')\n\nThe model showed a relatively good predictive power, with an R^2 of 0.66:\n\ncollect_metrics(lfit)[,c(1,3)]\n\n# A tibble: 2 × 2\n  .metric  .estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 rmse    119754.   \n2 rsq          0.661\n\n\nSpatial components, particularly longitude (as house prices are highest on both the West and East coasts), and the temporal component were key predictors, as seen in the variable importance:"
  },
  {
    "objectID": "posts/intrpl_houseprice.html#model-validation",
    "href": "posts/intrpl_houseprice.html#model-validation",
    "title": "Reconstructing historical house price dynamics across the United States without time series data",
    "section": "4. Model validation",
    "text": "4. Model validation\nTo validate the interpolation, I checked how well our model (trained solely on data without temporal replication) predicted house price changes compared to observed changes in real time series data. This involved randomly calculating log response ratios (lnRR) of price changes between two time points for each individual time series using both observed and predicted prices (repeated here 30 times).\n\n# Predict the model over the entire dataset\nst=Sys.time()\npreds &lt;- lfit %&gt;% \n  extract_workflow() %&gt;% \n  predict(zillow_dat)\nSys.time()-st\n\n\n# Merge price predictions to the data\nzillow_dat$.pred &lt;- preds$.pred\n\n\nset.seed(567)\nres_rsq &lt;- list()\ni_iter = 1:30\ni_save = sample(i_iter, 1) # save one random iteration for plotting\nfor (i in i_iter) {\n  di &lt;- zillow_dat %&gt;%\n    group_by(RegionName) %&gt;%\n    sample_n(2) %&gt;%\n    arrange(RegionName, time) %&gt;%\n    select(RegionName, time, .pred, price) %&gt;%\n    mutate(time_period = ifelse(time == max(time), 'T2', 'T1')) %&gt;% \n    ungroup()\n  di_change_obs &lt;- di %&gt;% \n    select(-.pred,-time) %&gt;% \n    spread(time_period, price) %&gt;%\n    mutate(lnRR_obs = log(T2/T1))\n  di_change_prd &lt;- di %&gt;% \n    select(-price,-time) %&gt;% \n    spread(time_period, .pred) %&gt;%\n    mutate(lnRR_prd = log(T2/T1))\n  di_change_join &lt;- left_join(\n    di_change_obs %&gt;% select(RegionName, lnRR_obs),\n    di_change_prd %&gt;% select(RegionName, lnRR_prd),\n    'RegionName'\n  ) \n  if(i == i_save) {\n    res_dat_example &lt;- di_change_join\n  }\n  res_rsq[[i]] &lt;- rsq(di_change_join, lnRR_obs, lnRR_prd)\n  if(i %% 10 == 0){\n    message('iter: ', i,'...done')\n  }\n}\nres_rsq &lt;- res_rsq %&gt;%\n  bind_rows(.id='iter')\n# round(range(res_rsq$.estimate), 2)\npaste0(\n  'rsq (pred. vs. obs. lnRR) = ', round(mean(res_rsq$.estimate), 2)\n)\n\n[1] \"rsq (pred. vs. obs. lnRR) = 0.62\"\n\n\nWe found our model to predict with high accuracy changes of prices over time (R^2 = 0.62). This means, indeed, that we can robustly predict temporal price series without temporal replication."
  },
  {
    "objectID": "posts/intrpl_houseprice.html#limitations-and-applications",
    "href": "posts/intrpl_houseprice.html#limitations-and-applications",
    "title": "Reconstructing historical house price dynamics across the United States without time series data",
    "section": "5. Limitations and Applications",
    "text": "5. Limitations and Applications\nOf course, we still have approximately 38% of unexplained variation, which means we cannot reconstruct site-specific trends with absolute certainty. While our approach is capable of predicting the average direction of changes across various sites with relatively good estimation, precise estimations at each region can still be very imprecise (especially in cities with trends that differ substantially from nearby neighborhoods), as you can see in some examples in the graphs below. This cautions against using this method for individual site time series forecasting, especially when the business goal is to obtain highly precise estimates. Nonetheless, I argue that this approach is extremely powerful for reconstructing overall temporal changes across many sparse observations, especially in scenarios where we have no alternative but to use data without temporal replication."
  },
  {
    "objectID": "posts/intrpl_houseprince/intrpl_houseprice.html",
    "href": "posts/intrpl_houseprince/intrpl_houseprice.html",
    "title": "Reconstructing 25 years of house price dynamics across the United States without time series data",
    "section": "",
    "text": "Time series data can often be gappy in space and time. Here, I illustrate a spatiotemporal machine learning (ML) interpolation exercise showing that it is possible to predict temporal changes at any point in time for a variable of interest from sparse geographic data (i.e., data without temporal replication at a site). This approach works when the variable of interest is spatially and temporally autocorrelated (Tobler, 1970), so that the space-time cube (Mahecha et al., 2020) can be filled using ML models trained on data with just one observation at each site that account for the complex interaction between space, time, and area (Keil & Chase, 2022).\nAs an ecologist by training, we recently utilized this approach to study species richness dynamics (Midolo et al., 2025). Here, I illustrate how this approach can be applied very well also in other contexts, such as the changes in prices of houses arranged across postal codes of the United States. Specifically, I utilized temporal time series of house prices across 26,318 zip addresses across the U.S. available from Zillow Housing Data. I used smoothed, seasonally adjusted, Zillow Home Value Index (ZHVI) prices for all homes tipes (SFR and Condo/Co-op). The time serie cover 25 years, ranging from 31 December 2000 to 31 March 2025."
  },
  {
    "objectID": "posts/intrpl_houseprince/intrpl_houseprice.html#background",
    "href": "posts/intrpl_houseprince/intrpl_houseprice.html#background",
    "title": "Reconstructing 25 years of house price dynamics across the United States without time series data",
    "section": "",
    "text": "Time series data can often be gappy in space and time. Here, I illustrate a spatiotemporal machine learning (ML) interpolation exercise showing that it is possible to predict temporal changes at any point in time for a variable of interest from sparse geographic data (i.e., data without temporal replication at a site). This approach works when the variable of interest is spatially and temporally autocorrelated (Tobler, 1970), so that the space-time cube (Mahecha et al., 2020) can be filled using ML models trained on data with just one observation at each site that account for the complex interaction between space, time, and area (Keil & Chase, 2022).\nAs an ecologist by training, we recently utilized this approach to study species richness dynamics (Midolo et al., 2025). Here, I illustrate how this approach can be applied very well also in other contexts, such as the changes in prices of houses arranged across postal codes of the United States. Specifically, I utilized temporal time series of house prices across 26,318 zip addresses across the U.S. available from Zillow Housing Data. I used smoothed, seasonally adjusted, Zillow Home Value Index (ZHVI) prices for all homes tipes (SFR and Condo/Co-op). The time serie cover 25 years, ranging from 31 December 2000 to 31 March 2025."
  },
  {
    "objectID": "posts/intrpl_houseprince/intrpl_houseprice.html#data-preparation",
    "href": "posts/intrpl_houseprince/intrpl_houseprice.html#data-preparation",
    "title": "Reconstructing 25 years of house price dynamics across the United States without time series data",
    "section": "2. Data preparation",
    "text": "2. Data preparation\nAs the Zillow dataset does not contain the longitude and latitude of ZIP code addresses, I utilized an external source containing geographic information for each ZIP code, available on kaggle.com. This dataset offers geographic coordinates in WGS84. I transformed these coordinates (x, y) into meters (using EPSG:5070 - NAD83/Conus Albers projection) so that we can use this information for better statistical interpolation. Concerning time, I standardized it so that it is expressed in days elapsed from the 1st of January 2000.\n\n# load R packages\nlibrary(tidyverse)\nlibrary(sf)\n\n# Load ZIP code 7geographic data (downloaded from: https://www.kaggle.com/datasets/jedwible/uszipcodes-20231227)\nzips &lt;- \"./data/USZipsWithLatLon_20231227.csv\" %&gt;%\n  read_csv(show_col_types = F) %&gt;%\n  # select variables of interest\n  select(`postal code`, latitude, longitude) %&gt;%\n  # add coordinates in meters (NAD83 / Conus Albers, EPSG:5070)\n  st_as_sf(coords = c('longitude','latitude'), remove = F, crs = 'WGS84') %&gt;%\n  st_transform(crs = 5070) %&gt;%\n  # transform back to dataframe object\n  as_Spatial() %&gt;%\n  as.data.frame() %&gt;%\n  rename(x=coords.x1, y=coords.x2)\n  \n# Load Zillow data (downloaded from: https://www.zillow.com/research/data)\nzillow_dat &lt;- './data/Zip_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv' %&gt;%\n  read_csv(show_col_types = F)\n\n# Merge Zillow data to geolocation data & tidy the data\nzillow_dat &lt;- zillow_dat %&gt;%\n  # merge coordinates to ZIP data\n  left_join(zips, by = c('RegionName' = 'postal.code')) %&gt;%\n  select(RegionName, longitude, latitude, x, y, everything() )%&gt;%\n  # gather price and time\n  gather('rawdate','price', 14:ncol(.), na.rm = T) %&gt;%\n  arrange(RegionName) %&gt;%\n  # extract date and calculate time (days) elapsed since baseline date (1st Jan 2000)\n  mutate(rawdate = as.Date(rawdate)) %&gt;%\n  mutate(time = as.numeric(rawdate - as.Date('2000-01-01'))) %&gt;%\n  group_by(RegionName) %&gt;%\n  mutate(time_span_years = max(time)-min(time), .after= RegionName) %&gt;%\n  ungroup()\n\nThe data comprehend time series for each ZIP code in the U.S. For example, here is how the temporal trend of prices looks in Beverly Hills (Los Angeles) - a region known for very high property values:\n\n\n\n\n\nThe time series covers each of these locations (however, note that not all ZIP codes have data across the entire 25 years period):"
  },
  {
    "objectID": "posts/intrpl_houseprince/intrpl_houseprice.html#model-training",
    "href": "posts/intrpl_houseprince/intrpl_houseprice.html#model-training",
    "title": "Reconstructing 25 years of house price dynamics across the United States without time series data",
    "section": "3. Model training",
    "text": "3. Model training\nI will employ Random Forests (Breiman, 2001) using the ‘ranger’ engine (Wright & Ziegler, 2017) to model the dependence of price to geographic coordiantes (x, y) and time. \\[\nprice \\sim x + y + time\n\\] Given repeated observations at each U.S. ZIP code, I tested the robustness of our temporal price interpolation by training our model on sites without replication in time. To this end, I generated a static dataset by randomly sampling one price observation at a random time for each U.S. ZIP code.\n\n# Generate random static dataset\nset.seed(123)\nd_static &lt;- zillow_dat %&gt;%\n  group_by(RegionName) %&gt;%\n  sample_n(1) %&gt;%\n  ungroup()\n\nThe space-time cube representation of our data is visualized below (showing 1000 observations only for clarity), with colored points being our response variable to be interpolated in time.\n\n\n\n\n\nI tuned and trained our model using tidymodels:\n\nlibrary(tidymodels)\nlibrary(future)\n\n# Prepare data for modeling and split train and test dataset\nset.seed(234)\ndat_split &lt;- \n  d_static %&gt;%\n  ## select variables for modeling\n  select(RegionName, price, x, y, time) %&gt;%\n  ## split the data\n  initial_split(prop = 4/5, strata = price)\n\n# Subset training set\ndat_train &lt;- training(dat_split) \n\n# Get CV folds\nset.seed(345)\ncv_random_folds &lt;- vfold_cv(dat_train, v = 10, repeats = 1, strata = price)\n\n# Define recipe\nrec &lt;- recipe(price ~ x + y + time, data = dat_train) %&gt;%\n  step_normalize(all_numeric_predictors())\n\n# Define model \nspec &lt;- rand_forest(\n  trees = 500, \n  min_n = tune(),\n  mtry = tune()\n) %&gt;%\n  set_mode('regression') %&gt;%\n  set_engine('ranger', importance = 'impurity', seed = 1975)\n\n# Define workflow\nwflow &lt;- workflow() %&gt;%\n  add_model(spec) %&gt;%\n  add_recipe(rec)\nwflow\n\n# Define tune grid\ngrd_tune &lt;- expand.grid(\n  min_n = c(2,5,10,15,20),\n  mtry = c(2:3)) %&gt;%\n  as_tibble()\nglimpse(grd_tune)\n\n# Perform tuning\nset.seed(456)\nplan(multisession, workers = 4)\nst = Sys.time()\ntune_res &lt;- tune_grid(\n  object = wflow,\n  resamples = cv_random_folds,\n  grid = grd_tune,\n  metrics = metric_set(rmse, rsq)\n)\nprint(Sys.time()-st)\nplan(sequential)\n\n# Export tuning results\ntune_res %&gt;%\n  write_rds('./data/models/RF.tune_res.rds')\n\n# Select the best performing sets of parameters\ntune_best &lt;- select_best(tune_res, metric = 'rmse')\ntune_best\n\n# Finalize workflow, fit on training data and test on testing data\nlfit &lt;- wflow %&gt;%\n  finalize_workflow(tune_best) %&gt;%\n  last_fit(dat_split)\n\n# Export last fit\nlfit %&gt;%\n  write_rds('./data/models/RF.last_fit.rds')\n\nThe model showed a relatively good predictive power, with an \\(R^{2}\\) of 0.66:\n\ncollect_metrics(lfit)[,c(1,3)]\n\n# A tibble: 2 × 2\n  .metric  .estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 rmse    119754.   \n2 rsq          0.661\n\n\nSpatial components, particularly longitude (as house prices are highest on both the West and East coasts), and the temporal component were key predictors, as seen in the variable importance:"
  },
  {
    "objectID": "posts/intrpl_houseprince/intrpl_houseprice.html#model-validation",
    "href": "posts/intrpl_houseprince/intrpl_houseprice.html#model-validation",
    "title": "Reconstructing 25 years of house price dynamics across the United States without time series data",
    "section": "4. Model validation",
    "text": "4. Model validation\nTo validate the interpolation, I checked how well our model (trained solely on data without temporal replication) predicted house price changes compared to observed changes in real time series data. This involved randomly calculating log response ratios (lnRR) of price changes between two time points for each individual time series using both observed and predicted prices (repeated here 30 times).\n\n# Predict the model over the entire dataset\nst=Sys.time()\npreds &lt;- lfit %&gt;% \n  extract_workflow() %&gt;% \n  predict(zillow_dat)\nSys.time()-st\n\n\n# Merge price predictions to the data\nzillow_dat$.pred &lt;- preds$.pred\n\n\nset.seed(567)\nres_rsq &lt;- list()\ni_iter = 1:30\ni_save = sample(i_iter, 1) # save one random iteration for plotting\nfor (i in i_iter) {\n  di &lt;- zillow_dat %&gt;%\n    group_by(RegionName) %&gt;%\n    sample_n(2) %&gt;%\n    arrange(RegionName, time) %&gt;%\n    select(RegionName, time, .pred, price) %&gt;%\n    mutate(time_period = ifelse(time == max(time), 'T2', 'T1')) %&gt;% \n    ungroup()\n  di_change_obs &lt;- di %&gt;% \n    select(-.pred,-time) %&gt;% \n    spread(time_period, price) %&gt;%\n    mutate(lnRR_obs = log(T2/T1))\n  di_change_prd &lt;- di %&gt;% \n    select(-price,-time) %&gt;% \n    spread(time_period, .pred) %&gt;%\n    mutate(lnRR_prd = log(T2/T1))\n  di_change_join &lt;- left_join(\n    di_change_obs %&gt;% select(RegionName, lnRR_obs),\n    di_change_prd %&gt;% select(RegionName, lnRR_prd),\n    'RegionName'\n  ) \n  if(i == i_save) {\n    res_dat_example &lt;- di_change_join\n  }\n  res_rsq[[i]] &lt;- rsq(di_change_join, lnRR_obs, lnRR_prd)\n  if(i %% 10 == 0){\n    message('iter: ', i,'...done')\n  }\n}\nres_rsq &lt;- res_rsq %&gt;%\n  bind_rows(.id='iter')\n\n\n#Average Rsq results\npaste0('rsq (pred. vs. obs. lnRR) = ', round(mean(res_rsq$.estimate), 2))\n\n[1] \"rsq (pred. vs. obs. lnRR) = 0.62\"\n\n\nOur model predicted with good accuracy changes of prices over time (\\(R^{2}\\) = 0.62). This means, indeed, that we can robustly predict temporal price series without temporal replication."
  },
  {
    "objectID": "posts/intrpl_houseprince/intrpl_houseprice.html#limitations-and-applications",
    "href": "posts/intrpl_houseprince/intrpl_houseprice.html#limitations-and-applications",
    "title": "Reconstructing 25 years of house price dynamics across the United States without time series data",
    "section": "5. Limitations and Applications",
    "text": "5. Limitations and Applications\nOf course, we still have 38% of unexplained variation in price changes, which means we cannot reconstruct site-specific trends with absolute certainty. While our approach is capable of predicting the average direction of changes across various regions (=ZIP codes) with relatively good estimation, price estimations at each region can still be very imprecise (especially in those ZIP codes/cities with temporal trends that differ substantially from nearby neighborhoods, breaking the spatial dependency needed for predictions), as you can see in some examples in the graphs below. This cautions against using this method for individual site time series forecasting, especially when the goal is to obtain highly precise estimates. Nonetheless, I argue that this approach is extremely powerful for reconstructing overall temporal changes across many sparse observations, especially in scenarios where we have no alternative but to use data without temporal replication."
  },
  {
    "objectID": "posts/intrpl_houseprince/intrpl_houseprice.html#references",
    "href": "posts/intrpl_houseprince/intrpl_houseprice.html#references",
    "title": "Reconstructing 25 years of house price dynamics across the United States without time series data",
    "section": "References",
    "text": "References\n\nBreiman L., Random forests. Machine Learning 45, 5–32 (2001).\nKeil, P. & Chase, J. Interpolation of temporal biodiversity change, loss, and gain across scales: a machine learning approach. EcoEvoRxiv (2022)\nMahecha, M. D. et al. Earth system data cubes unravel global multivariate dynamics. Earth System Dynamics 11, 201–234 (2020)\nMidolo, G. et al. Six decades of losses and gains in alpha diversity of European plant communities. EcoEvoRxiv https://doi.org/10.32942/X2164H (2025).\nTobler, W. R. A Computer Movie Simulating Urban Growth in the Detroit Region. Economic Geography 46, 234 (1970)\nWright, M. N. & Ziegler, A. ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R. Journal of Statistical Software 77 (2017)."
  },
  {
    "objectID": "old_posts/ts_sentiments/ts_sentiment.html",
    "href": "old_posts/ts_sentiments/ts_sentiment.html",
    "title": "Taylored Sentiments",
    "section": "",
    "text": "Here I use sentiment analysis\n\n\n\n\nAI-generated using OpenAI tools. Free for non-commercial use with attribution."
  },
  {
    "objectID": "contact_me.html",
    "href": "contact_me.html",
    "title": "Contact Me",
    "section": "",
    "text": "Contact Me\nPlease feel free to reach out through any of the methods below\n\n📧 Email\ngabriele.midolo@gmail.com\n\n\n💬 Social Media\n\nLinkedIn\nGitHub\nTwitter"
  },
  {
    "objectID": "contact_me.html#email",
    "href": "contact_me.html#email",
    "title": "Contact Me",
    "section": "",
    "text": "You can email me at:\ngabriele.midolo@gmail.com"
  },
  {
    "objectID": "contact_me.html#social-media",
    "href": "contact_me.html#social-media",
    "title": "Contact Me",
    "section": "",
    "text": "LinkedIn\nGitHub\nTwitter"
  },
  {
    "objectID": "contact_me.html#phone",
    "href": "contact_me.html#phone",
    "title": "Contact Me",
    "section": "Phone",
    "text": "Phone\n +39 3703185439"
  }
]